{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from epi.normalizing_flows import NormalizingFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_lu_factorization(event_size, batch_shape=(), seed=None, dtype=tf.float32, name=None):\n",
    "    with tf.name_scope(name or 'trainable_lu_factorization'):\n",
    "        event_size = tf.convert_to_tensor(event_size, dtype_hint=tf.int32, name='event_size')\n",
    "        batch_shape = tf.convert_to_tensor(batch_shape, dtype_hint=event_size.dtype, name='batch_shape')\n",
    "        random_matrix = tf.random.uniform(\n",
    "            shape=tf.concat([batch_shape, [event_size, event_size]], axis=0),\n",
    "            dtype=dtype,\n",
    "            seed=seed)\n",
    "        random_orthonormal = tf.linalg.qr(random_matrix)[0]\n",
    "        lower_upper, permutation = tf.linalg.lu(random_orthonormal)\n",
    "        lower_upper = tf.Variable(\n",
    "            initial_value=lower_upper,\n",
    "            trainable=True,\n",
    "            name='lower_upper')\n",
    "        # Initialize a non-trainable variable for the permutation indices so\n",
    "        # that its value isn't re-sampled from run-to-run.\n",
    "        permutation = tf.Variable(\n",
    "            initial_value=permutation,\n",
    "            trainable=False,\n",
    "            name='permutation')\n",
    "    return lower_upper, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'trainable_lu_factorization/lower_upper:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.59904504,  0.52042955,  0.6082792 , -0.01715939],\n",
      "       [ 0.89346045, -1.1430819 , -0.5045728 , -0.486869  ],\n",
      "       [ 0.9515199 ,  0.23153283, -1.2138451 ,  0.36701193],\n",
      "       [ 0.28806114,  0.53790987, -0.28628635,  1.2030947 ]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'trainable_lu_factorization/permutation:0' shape=(4,) dtype=int32, numpy=array([0, 2, 3, 1], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "lower_upper, perm = trainable_lu_factorization(4)\n",
    "print(lower_upper)\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-df65b3990ed4>:2: MatvecLU.__init__ (from tensorflow_probability.python.bijectors.scale_matvec_lu) is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`MatvecLU` has been deprecated and renamed `ScaleMatvecLU`; please use that symbol instead.\n",
      "<tensorflow_probability.python.bijectors.scale_matvec_lu.MatvecLU object at 0x7f88d07aec50>\n"
     ]
    }
   ],
   "source": [
    "bij = tfp.bijectors.MatvecLU(\n",
    "    lower_upper, perm, validate_args=False, name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.9541798 -0.6462333  0.4466392 -0.8013915], shape=(4,), dtype=float32)\n",
      "tf.Tensor(-1.937151e-07, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(0., 1., (4,)).astype(np.float32)\n",
    "print(bij(x))\n",
    "print(bij.forward_log_det_jacobian(x, event_ndims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<epi.normalizing_flows.NormalizingFlow object at 0x7f88d10ec320>\n"
     ]
    }
   ],
   "source": [
    "D = 2\n",
    "#lb = -1*np.ones((D,))\n",
    "#ub = 1*np.ones((D,))\n",
    "nf = NormalizingFlow(\n",
    "    \"coupling\", D, 2, 2, 25, batch_norm=False,\n",
    "    num_bins=32, elemwise_fn=\"spline\",\n",
    "    post_affine=True, random_seed=1,\n",
    "    #post_affine=True, bounds=(lb,ub), random_seed=1,\n",
    ")\n",
    "print(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z, log_q_z = nf(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([(), <epi.normalizing_flows.SplineParams object at 0x7fa631ecaef0>, (), <epi.normalizing_flows.SplineParams object at 0x7fa62e3fd518>])\n"
     ]
    }
   ],
   "source": [
    "print(nf.bijector_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/w/kernel:0' shape=(1, 32) dtype=float32, numpy=\n",
      "array([[ 0.4226386 ,  0.22016853,  0.08234906,  0.02216202, -0.3641784 ,\n",
      "         0.08509195, -0.22607428, -0.38135204, -0.20102943,  0.25581813,\n",
      "         0.25211662,  0.33974403,  0.1887958 ,  0.37081164, -0.348355  ,\n",
      "        -0.08980599, -0.21058312,  0.08387399,  0.41272944, -0.1485582 ,\n",
      "        -0.30277687,  0.2192108 , -0.3595749 ,  0.01056543, -0.10300162,\n",
      "        -0.34355605,  0.17857444,  0.4082812 , -0.07055354, -0.04112777,\n",
      "        -0.15531081,  0.22308838]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/w/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/h/kernel:0' shape=(1, 32) dtype=float32, numpy=\n",
      "array([[-0.24377292,  0.09346706, -0.03335997, -0.1520679 ,  0.02330491,\n",
      "        -0.21873601, -0.4005627 ,  0.15323943,  0.07029036,  0.08902532,\n",
      "         0.06929082,  0.22819048, -0.33662522,  0.4170469 ,  0.14610368,\n",
      "         0.04135203, -0.04299897,  0.00244427,  0.3712262 , -0.21627793,\n",
      "        -0.0990544 ,  0.04178339,  0.32930893,  0.23799354, -0.38480458,\n",
      "         0.094019  ,  0.23836148, -0.07595313, -0.15173668,  0.26326054,\n",
      "        -0.27301186, -0.04715827]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/h/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/s/kernel:0' shape=(1, 31) dtype=float32, numpy=\n",
      "array([[ 0.23238078,  0.06968471,  0.26980302, -0.02505738,  0.37443754,\n",
      "        -0.23056626, -0.24766243,  0.1157687 , -0.35623956,  0.41644964,\n",
      "         0.3954501 , -0.1015113 , -0.00829458, -0.19493245,  0.28141245,\n",
      "         0.14849463, -0.33437556, -0.14414129,  0.19263735,  0.3602037 ,\n",
      "        -0.35914838,  0.4150289 , -0.10044175,  0.40050182,  0.17103204,\n",
      "         0.3084074 ,  0.32488444,  0.4071068 , -0.17413136, -0.04229569,\n",
      "        -0.0039182 ]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/s/bias:0' shape=(31,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/w/kernel:0' shape=(1, 32) dtype=float32, numpy=\n",
      "array([[ 0.34943503,  0.11416107,  0.20486492, -0.202201  ,  0.29707462,\n",
      "         0.25661415, -0.22469127, -0.02543065,  0.16269058, -0.22189872,\n",
      "        -0.15579656, -0.19026363, -0.16795176,  0.19280761, -0.11603978,\n",
      "         0.28167152, -0.26211613,  0.1322996 , -0.41958693, -0.2660486 ,\n",
      "        -0.2549947 , -0.21613234, -0.3708477 ,  0.35191578, -0.12031254,\n",
      "        -0.04937828, -0.17573348,  0.42513597,  0.19879878,  0.17177212,\n",
      "        -0.13022965,  0.3034346 ]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/w/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/h/kernel:0' shape=(1, 32) dtype=float32, numpy=\n",
      "array([[ 0.28326315,  0.3517251 ,  0.07878166, -0.10976622, -0.2180444 ,\n",
      "        -0.3761374 ,  0.15935725,  0.15026367,  0.41538382,  0.29257983,\n",
      "         0.33840656, -0.06077844, -0.29200178,  0.28886205,  0.40827185,\n",
      "         0.01091626, -0.14362901,  0.21782047, -0.13671297,  0.08161622,\n",
      "         0.11606783, -0.36772475,  0.07252273, -0.04262373,  0.27513498,\n",
      "        -0.42063528,  0.27490306, -0.21780916,  0.33377755, -0.193816  ,\n",
      "         0.06016886, -0.31183577]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/h/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/s/kernel:0' shape=(1, 31) dtype=float32, numpy=\n",
      "array([[-0.218497  ,  0.0598717 , -0.15923831, -0.08362722,  0.1413115 ,\n",
      "        -0.3381105 ,  0.35592625,  0.3490816 , -0.28453448, -0.42259905,\n",
      "        -0.23521188,  0.33815953, -0.32799512, -0.35838145,  0.25979128,\n",
      "        -0.06081456, -0.10642451, -0.13789031, -0.18503384,  0.2951961 ,\n",
      "        -0.18455575,  0.09778437,  0.30357262,  0.20265827,  0.3517324 ,\n",
      "         0.36449066,  0.24936584,  0.0212608 ,  0.05479485,  0.16248658,\n",
      "        -0.08425492]], dtype=float32)>\n",
      "<tf.Variable 'real_nvp/forward_log_det_jacobian/s/bias:0' shape=(31,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'a:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>\n",
      "<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "for param in nf.trainable_variables:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to broadcast spline parameters over batch dimension as well.\n",
    "\"Reshaping acrobatics needed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SplineParams(tf.Module):\n",
    "\n",
    "    def __init__(self, nunits, nbins=32):\n",
    "        self._nunits = nunits\n",
    "        self._nbins = nbins\n",
    "        self._built = False\n",
    "        self._bin_widths = None\n",
    "        self._bin_heights = None\n",
    "        self._knot_slopes = None\n",
    "\n",
    "    def _bin_positions(self, x):\n",
    "        x = tf.reshape(x, [-1, self._nunits, self._nbins])\n",
    "        return tf.math.softmax(x, axis=-1) * (2 - self._nbins * 1e-2) + 1e-2\n",
    "\n",
    "    def _slopes(self, x):\n",
    "        x = tf.reshape(x, [-1, self._nunits, self._nbins - 1])\n",
    "        return tf.math.softplus(x) + 1e-2\n",
    "\n",
    "    def __call__(self, x, nunits):\n",
    "        if not self._built:\n",
    "            self._bin_widths = tf.keras.layers.Dense(\n",
    "              nunits * self._nbins, activation=self._bin_positions, name='w')\n",
    "            self._bin_heights = tf.keras.layers.Dense(\n",
    "              nunits * self._nbins, activation=self._bin_positions, name='h')\n",
    "            self._knot_slopes = tf.keras.layers.Dense(\n",
    "              nunits * (self._nbins - 1), activation=self._slopes, name='s')\n",
    "            self._built = True\n",
    "        return tfb.RationalQuadraticSpline(\n",
    "            bin_widths=self._bin_widths(x),\n",
    "            bin_heights=self._bin_heights(x),\n",
    "            knot_slopes=self._knot_slopes(x))\n",
    "    \n",
    "N = 100 # batch size\n",
    "D = 15 # dimensionality\n",
    "nsplits = 3\n",
    "\n",
    "xs = np.random.randn(N, D).astype(np.float32)  # Keras won't Dense(.)(vec).\n",
    "nmasked = [5*i for i in range(nsplits)] # dimensions to mask in RealNVP\n",
    "nunits = [D - x for x in nmasked]\n",
    "splines = [SplineParams(nunits[i]) for i in range(nsplits)]\n",
    "\n",
    "def spline_flow():\n",
    "    stack = tfb.Identity()\n",
    "    for i in range(nsplits):\n",
    "        stack = tfb.RealNVP(nmasked[i], bijector_fn=splines[i])(stack)\n",
    "    return stack\n",
    "\n",
    "ys = spline_flow().forward(xs)\n",
    "ys_inv = spline_flow().inverse(ys)  # ys_inv ~= xs\n",
    "assert(np.isclose(xs, ys_inv).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100 # batch size\n",
    "D = 15 # dimensionality\n",
    "nsplits = 3\n",
    "\n",
    "xs = np.random.randn(N, D).astype(np.float32)  # Keras won't Dense(.)(vec).\n",
    "nmasked = [5*i for i in range(nsplits)] # dimensions to mask in RealNVP\n",
    "nunits = [D - x for x in nmasked]\n",
    "splines = [SplineParams(nunits[i]) for i in range(nsplits)]\n",
    "\n",
    "def spline_flow():\n",
    "    stack = tfb.Identity()\n",
    "    for i in range(nsplits):\n",
    "        stack = tfb.RealNVP(nmasked[i], bijector_fn=splines[i])(stack)\n",
    "    return stack\n",
    "\n",
    "ys = spline_flow().forward(xs)\n",
    "ys_inv = spline_flow().inverse(ys)  # ys_inv ~= xs\n",
    "assert(np.isclose(xs, ys_inv).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 15\n",
    "num_masked = 7\n",
    "xs = np.random.randn(1, D).astype(np.float32)  # Keras won't Dense(.)(vec).\n",
    "nunits = D - num_masked\n",
    "spline = SplineParams(nunits)\n",
    "\n",
    "#def spline_flow():\n",
    "nvp = tfb.RealNVP(num_masked, bijector_fn=spline)\n",
    "#return stack\n",
    "\n",
    "#ys = spline_flow().forward(xs)\n",
    "#ys_inv = spline_flow().inverse(ys)  # ys_inv ~= xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SplineParams object at 0x7ff6bbf0e470>\n"
     ]
    }
   ],
   "source": [
    "s = splines[1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = s(xs[:,:5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow_probability.python.bijectors.rational_quadratic_spline.RationalQuadraticSpline object at 0x7ff6bbe85518>\n",
      "tf.Tensor(\n",
      "[[-1.3599697   0.1139448   0.8640732  -0.82076377 -2.0931187  -0.5929633\n",
      "   0.48693687  0.7457276   0.43292007 -0.56522083]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(f(xs[:,:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_units = 25\n",
    "f = tfb.real_nvp_default_template(\n",
    "    hidden_layers=num_layers * [num_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.template.EagerTemplate object at 0x7fa5086b7fd0>\n"
     ]
    }
   ],
   "source": [
    "f = tfb.RationalQuadraticSpline(\n",
    "        bin_widths=self._bin_widths(x),\n",
    "        bin_heights=self._bin_heights(x),\n",
    "        knot_slopes=self._knot_slopes(x))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 10\n",
    "D = 4\n",
    "x = np.random.normal(0., 1., (M,D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10, 2)\n",
      "tf.Tensor([-0.0893935   0.32305841], shape=(2,), dtype=float64) tf.Tensor([-0.22781825  0.53631505], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a, b = f(x, 2)\n",
    "print(a.shape, b.shape)\n",
    "print(a[0,:], b[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "lb = -1*np.ones((D,))\n",
    "ub = 1*np.ones((D,))\n",
    "nf = NormalizingFlow(\n",
    "    \"coupling\", D, 2, 2, 25, batch_norm=True,\n",
    "    post_affine=True, bounds=(lb,ub), random_seed=1,\n",
    ")\n",
    "mu = .75*np.ones((D,))\n",
    "Sigma = .25*np.eye(D)\n",
    "#nf.initialize(mu, Sigma, num_iters=int(10e3), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epi)",
   "language": "python",
   "name": "epi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
