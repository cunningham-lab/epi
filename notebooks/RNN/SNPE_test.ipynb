{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"SNPE: RNN stable amplification. \"\"\"\n",
    "\n",
    "from neural_circuits.LRRNN import get_W_eigs_np\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import delfi\n",
    "from delfi.simulator.BaseSimulator import BaseSimulator\n",
    "import delfi.distribution as dd\n",
    "from delfi.summarystats.BaseSummaryStats import BaseSummaryStats\n",
    "from scipy import stats as spstats\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "\n",
    "DTYPE = np.float32\n",
    "\n",
    "N = 2\n",
    "n_train = 1000\n",
    "n_mades = 1\n",
    "n_atoms = 25\n",
    "g = 0.\n",
    "K = 1\n",
    "rs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charming-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SNPE on RNN conditioned on stable amplification with:\n",
      "N = 2, n_train = 1000, n_mades = 1, n_atoms = 25, seed=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b0e2a87c4a4b2c98a56e9c715c5b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d563d3908dd04cd1b1f71d2650461ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63637406730c4ea98581a438e1d14d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd84c85b569943e599aac5ae40563617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbb66702a8940669766146e3b482b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bffda9600a7465f8e1478f6afdd50ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8a6f99283688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    184\u001b[0m optim = {'logs':logs,\n\u001b[1;32m    185\u001b[0m          \u001b[0;34m'trn_datasets'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrn_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m          'times':times}\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0mnets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'posteriors'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mposteriors\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "print('Running SNPE on RNN conditioned on stable amplification with:')\n",
    "print('N = %d, n_train = %d, n_mades = %d, n_atoms = %d, seed=%d' \\\n",
    "      % (N, n_train, n_mades, n_atoms, rs))\n",
    "\n",
    "base_path = os.path.join(\"data\", \"snpe\")\n",
    "save_dir = \"SNPE_RNN_stab_amp_N=%d_ntrain=%dk_nmades=%d_natoms=%d_rs=%d\" \\\n",
    "        % (N, n_train//1000, n_mades, n_atoms, rs)\n",
    "\n",
    "save_path = os.path.join(base_path, save_dir)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "if os.path.exists(os.path.join(base_path, save_dir, \"optim.pkl\")):\n",
    "    print(\"SNPE optimization already run. Exitting.\")\n",
    "    exit()\n",
    "\n",
    "_W_eigs = get_W_eigs_np(g, K)\n",
    "\n",
    "def W_eigs(params, seed=None):\n",
    "    \"\"\"Calculates Jeigs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : np.array, 1d of length dim_param\n",
    "            Parameter vector\n",
    "        seed : int\n",
    "        \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        rng = np.random.RandomState(seed=seed)\n",
    "    else:\n",
    "        rng = np.random.RandomState()\n",
    "\n",
    "    params = params\n",
    "\n",
    "    U = np.reshape(params[0,:(2*N)], (N,2))\n",
    "    V = np.reshape(params[0,(2*N):], (N,2))\n",
    "\n",
    "    x = _W_eigs(U, V)\n",
    "    return x\n",
    "\n",
    "class RNN(BaseSimulator):\n",
    "    def __init__(self, N, seed=None):\n",
    "        \"\"\"Hodgkin-Huxley simulator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int or None\n",
    "            Number of neurons.\n",
    "        seed : int or None\n",
    "            If set, randomness across runs is disabled\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.r = 2\n",
    "        dim_param = self.N*self.r*2\n",
    "\n",
    "        super().__init__(dim_param=dim_param, seed=seed)\n",
    "        self.Jeigs = W_eigs\n",
    "\n",
    "    def gen_single(self, params):\n",
    "        \"\"\"Forward model for simulator for single parameter set\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : list or np.array, 1d of length dim_param\n",
    "            Parameter vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict : dictionary with data\n",
    "            The dictionary must contain a key data that contains the results of\n",
    "            the forward run. Additional entries can be present.\n",
    "        \"\"\"\n",
    "        params = np.asarray(params)\n",
    "\n",
    "        assert params.ndim == 1, 'params.ndim must be 1'\n",
    "\n",
    "        Jeig_seed = self.gen_newseed()\n",
    "\n",
    "        states = self.Jeigs(params.reshape(1, -1), seed=Jeig_seed)\n",
    "\n",
    "        return {'data': states}\n",
    "\n",
    "seed_p = 1\n",
    "prior_min = -np.ones((4*N,))\n",
    "prior_max = np.ones((4*N,))\n",
    "prior = dd.Uniform(lower=prior_min, upper=prior_max,seed=seed_p)\n",
    "\n",
    "class RNNStats(BaseSummaryStats):\n",
    "    \"\"\"Moment based SummaryStats class for the Hodgkin-Huxley model\n",
    "\n",
    "    Calculates summary statistics\n",
    "    \"\"\"\n",
    "    def __init__(self, seed=None):\n",
    "        \"\"\"See SummaryStats.py for docstring\"\"\"\n",
    "        super(RNNStats, self).__init__(seed=seed)\n",
    "\n",
    "    def calc(self, repetition_list):\n",
    "        \"\"\"Calculate summary statistics\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        repetition_list : list of dictionaries, one per repetition\n",
    "            data list, returned by `gen` method of Simulator instance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array, 2d with n_reps x n_summary\n",
    "        \"\"\"\n",
    "        stats = []\n",
    "        if len(repetition_list) > 1:\n",
    "            print(repetition_list)\n",
    "            raise NotImplementedError()\n",
    "        for r in range(len(repetition_list)):\n",
    "            x = repetition_list[r]\n",
    "\n",
    "            stats.append(x['data'])\n",
    "        return np.asarray(stats)\n",
    "\n",
    "seed = 0\n",
    "# define model, prior, summary statistics and generator classes\n",
    "m = RNN(N=N)\n",
    "s = RNNStats()\n",
    "g = dg.Default(model=m, prior=prior, summary=s)\n",
    "\n",
    "n_processes = 4\n",
    "\n",
    "seeds_m = np.arange(1,n_processes+1,1)\n",
    "m = []\n",
    "for i in range(n_processes):\n",
    "    m.append(RNN(N=N, seed=seeds_m[i]))\n",
    "g = dg.MPGenerator(models=m, prior=prior, summary=s)\n",
    "\n",
    "# true parameters and respective labels\n",
    "true_params = np.random.uniform(-1., 1., (4*N,))\n",
    "labels_params = [r'$T_1$', r'$T_2$']\n",
    "\n",
    "# observed data: simulation given true parameters\n",
    "obs = m[0].gen_single(true_params)\n",
    "\n",
    "obs_stats = np.array([0.5, 1.5])\n",
    "\n",
    "pilot_samples = n_train\n",
    "\n",
    "# training schedule\n",
    "n_rounds = 2\n",
    "\n",
    "# fitting setup\n",
    "minibatch = 100\n",
    "epochs = 100\n",
    "val_frac = 0.05\n",
    "\n",
    "# network setup\n",
    "n_hiddens = [50,50]\n",
    "\n",
    "# convenience\n",
    "prior_norm = False\n",
    "\n",
    "# MAF parameters\n",
    "density = 'maf'\n",
    "\n",
    "# inference object\n",
    "res = infer.SNPEC(g,\n",
    "                obs=obs_stats,\n",
    "                n_hiddens=n_hiddens,\n",
    "                pilot_samples=pilot_samples,\n",
    "                n_mades=n_mades,\n",
    "                prior_norm=prior_norm,\n",
    "                density=density,\n",
    "                seed=rs)\n",
    "\n",
    "# train\n",
    "logs, trn_datasets, posteriors = res.run(\n",
    "                    n_train=n_train,\n",
    "                    n_rounds=n_rounds,\n",
    "                    n_atoms=n_atoms,\n",
    "                    minibatch=minibatch,\n",
    "                    epochs=epochs,\n",
    "                    silent_fail=False,\n",
    "                    proposal='prior',\n",
    "                    val_frac=val_frac,\n",
    "                    verbose=True,)\n",
    "\n",
    "optim = {'logs':logs,\n",
    "         'trn_datasets':trn_datasets,\n",
    "         'times':times}\n",
    "nets = {'posteriors':posteriors}\n",
    "\n",
    "base_path = os.path.join(\"data\", \"snpe\")\n",
    "save_dir = \"SNPE_RNN_stab_amp_N=%d_ntrain=%dk_nmades=%d_natoms=%d_rs=%d\" \\\n",
    "        % (N, n_train//1000, n_mades, n_atoms, rs)\n",
    "\n",
    "save_path = os.path.join(base_path, save_dir)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "print('Saving', save_path, '...')\n",
    "with open(os.path.join(base_path, save_dir, \"optim.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(optim, f)\n",
    "with open(os.path.join(base_path, save_dir, \"networks.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(nets, f)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (delfi)",
   "language": "python",
   "name": "delfi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
