\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}}
\citation{abbott2008theoretical}
\citation{hopfield1982neural}
\citation{sompolinsky1988chaos}
\citation{tsodyks1997paradoxical}
\citation{wong2006recurrent}
\citation{foster1993significance}
\citation{prinz2004similar}
\citation{achard2006complex}
\citation{o2014cell}
\citation{alonso2019visualization}
\citation{kass2001spike}
\citation{brown1998statistical}
\citation{paninski2004maximum}
\citation{truccolo2005point}
\citation{schneidman2006weak}
\citation{druckmann2007novel}
\citation{turner2007maximum}
\citation{byron2009gaussian}
\citation{macke2011empirical}
\citation{park2011bayesian}
\citation{granot2013stimulus}
\citation{latimer2015single}
\citation{lakshminarasimhan2018dynamic}
\citation{duncker2019learning}
\citation{ladenbauer2019inferring}
\citation{paninski2018neural}
\citation{sisson2007sequential}
\citation{liepe2014framework}
\citation{kingma2013auto}
\citation{rezende2014stochastic}
\citation{gao2016linear}
\citation{zhao2017recursive}
\citation{barello2018sparse}
\citation{pandarinath2018inferring}
\citation{wiltschko2015mapping}
\citation{johnson2016composing}
\citation{batty2019behavenet}
\citation{paninski2018neural}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{2}}
\citation{gelman2013philosophy}
\citation{blei2014build}
\citation{transtrum2015perspective}
\citation{tran2017hierarchical}
\citation{rezende2015variational}
\citation{dinh2016density}
\citation{papamakarios2017masked}
\citation{loaiza2017maximum}
\citation{goldman2001global}
\citation{litwin2016inhibitory}
\citation{duan2018collicular}
\citation{marder2002cellular}
\citation{goldman2001global}
\citation{prinz2004similar}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivating emergent property inference of theoretical models}{4}}
\newlabel{results_motivating}{{3.1}{4}}
\citation{gutierrez2013multiple}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Emergent property inference (EPI) in the stomatogastric ganglion. \textbf  {A}. Conductance-based biophysical model of the STG subcircuit. In the STG model, jagged connections indicate electrical coupling having electrical conductance $g_{\text  {el}}$. Other connections in the diagram are inhibitory synaptic projections having strength $g_{\text  {synA}}$ onto the hub neuron, and $g_{\text  {synB}}=5$nS for mutual inhibitory connections. Parameters are represented by the vector $\mathbf  {z}$ and membrane potentials by the vector $\mathbf  {x}$. The evolution of this model's activity $\mathbf  {x}(t)$ is predicated by differential equations. \textbf  {B}. Spiking frequency $\omega (\mathbf  {x}; \mathbf  {z})$ is an emergent property statistic. Spiking frequency is measured from simulated activity of the STG model at parameter choices of $g_{\text  {el}} = 4.5$nS and $g_{\text  {synA}} = 3$nS. \textbf  {C}. The emergent property of intermediate hub frequency, in which the hub neuron fires at a rate between the fast and slow frequencies. Simulated activity traces are colored by log probability density of their generating parameters in the EPI-inferred distribution (Panel E). \textbf  {D}. For a choice of model and emergent property, emergent property inference (EPI) learns a distribution of the model parameters $\mathbf  {z} = \left [g_{\text  {el}}, g_{\text  {synA}} \right ]$ producing intermediate hub frequency. Deep probability distributions map a simple random variable $\mathbf  {z}_0$ through a deep neural network with weights and biases $\bm  {\theta }$ to parameters $\mathbf  {z} = g_{\bm  {\theta }}(\mathbf  {z}_0)$ distributed as $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X})$. In EPI optimization, stochastic gradient steps in $\bm  {\theta }$ are taken such that entropy is maximized, and the emergent property $\mathcal  {X}$ is produced. \textbf  {E}. The EPI distribution of STG model parameters producing intermediate hub frequency. Samples are colored by log probability density. Distribution contours of hub neuron frequency from mean of .55 Hz are shown at levels of $.525$, $.53$, ... $.575$ Hz (dark to light gray away from mean). Frequencies are averages over the stochasticity of the model. Eigenvectors of the Hessian at the mode of the inferred distribution are indicated as $\mathbf  {v}_1$ (solid) and $\mathbf  {v}_2$ (dashed) with lengths scaled by the square root of the absolute value of their eigenvalues. Simulated activity is shown for three samples (stars). \textbf  {F} Simulations from parameters in E. (Top) The predictive distribution of the posterior obeys the constraints stipulated by the emergent property. The black and gray dashed lines show the mean and two standard deviations according the emergent property, respectively. (Bottom) Simulations at the starred parameter values. }}{6}}
\newlabel{fig:STG}{{1}{6}}
\citation{rezende2015variational}
\citation{dinh2016density}
\citation{papamakarios2017masked}
\citation{jaynes1957information}
\citation{elsayed2017structure}
\citation{loaiza2017maximum}
\citation{savin2017maximum}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}A deep generative modeling approach to emergent property inference}{7}}
\newlabel{results_dgm}{{3.2}{7}}
\newlabel{eq:EP_STG}{{2}{7}}
\newlabel{eq:EPI}{{3}{7}}
\citation{tsodyks1997paradoxical}
\citation{goldman2009memory}
\citation{murphy2009balanced}
\citation{ozeki2009inhibitory}
\citation{rubin2015stabilized}
\citation{markram2004interneurons}
\citation{rudy2011three}
\citation{tremblay2016}
\citation{pfeffer2013inhibition}
\citation{litwin2016inhibitory}
\citation{GarciaDelMolino2017}
\citation{Chen2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}EPI reveals how noise across neural population types governs Fano factor in a stochastic inhibition stabilized network}{8}}
\newlabel{results_V1}{{3.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Emergent property inference of a stochastic stabilized supralinear network. \textbf  {A}. Four-population model of primary visual cortex with excitatory (black), parvalbumin (blue), somatostatin (red), and VIP (green) neurons (excitatory and inhibitory projections filled and unfilled, respectively). Some neuron-types largely do not form synaptic projections to others ($|W_{\alpha _1, \alpha _2})| < 0.025$). Each neural population receives a baseline input $\mathbf  {h}_b$, and the E- and P-populations also receive a contrast-dependent input $\mathbf  {h}_b$. Additionally, each neural population receives a slow noisy input $\bm  {\epsilon }$. \textbf  {B}. Responses of the deterministic smodel ($\bm  {\epsilon }=\bm  {0}$) to varying contrasts. The response at 50\% contrast (dots) is the focus of our analysis. \textbf  {C}. Paradoxical response of the stochastic model to a small increase in input to the P-population. \textbf  {D}. EPI posterior of noise parameteres $\mathbf  {z}$ conditioned on realistic E-population Fano factors. The posterior predictive distribution is show on the bottom-left. and the mode of the distribution is starred. \textbf  {E}. (Top) Enlarged visualization of the $\sigma _E$-$\sigma _P$ marginal distribution of the posterior. Each gray dot is a choice of $\sigma _P$, for which a constrained mode $z^*(\sigma _P, P)$ is chosen. The arrows show the most sensitive dimensions of the Hessian evaluated at these modes. (Bottom) Such sensitive dimensions of the Hessian (dots) are significantly more sensitive than randomly chosen dimensions (box and whiskers). \textbf  {F}. The Fano factor of the E-population is strongly correlated with each other neuron-type population. \textbf  {G}. Mean and standard deviation (across EPI posterior) of Fano factor of each neuron-type population at each level of contrast. }}{9}}
\newlabel{fig:V1}{{2}{9}}
\citation{hennequin2018dynamical}
\citation{palmigiano2020structure}
\citation{duan2015requirement}
\citation{duan2018collicular}
\newlabel{eq:EP_V1}{{8}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}EPI identifies neural mechanisms of flexible task switching}{11}}
\newlabel{results_SC}{{3.4}{11}}
\newlabel{eq:EP}{{10}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {A}. Rapid task switching behavioral paradigm (see text). \textbf  {B}. Model of superior colliculus (SC). Neurons: LP - left pro, RP - right pro, LA - left anti, RA - right anti. Parameters: $sW$ - self, $hW$ - horizontal, $vW$ -vertical, $dW$ - diagonal weights. Subscripts $P$ and $A$ of connectivity weights indicate Pro or Anti populations. \textbf  {C}. The EPI parameter distribution of rapid task switching networks. Black star indicates parameter choice of simulations (D). \textbf  {D}. Simulations of an SC network from the EPI distribution with 75\% accuracy in each task. Top row shows no inactivation during Pro and Anti trials, and bottom row shows simulations with delay period inactivation (optogenetic strength $\gamma =0.7$). Shading indicates standard deviation across trials. \textbf  {E}. Difference in performance of each task during inactivation. Inactivation level ``opto strength" scales from no inactivation (0) to full inactivation (1). We compare delay period inactivation $1.2 < t < 1.5$ (blue), choice period inactivation $1.5 < t$ (red), and total inactivation $0 \leq t \leq 1.8$ (purple). \textbf  {F}. The effect of delay period inactivation on Anti accuracy versus dynamics eigenvalues. }}{13}}
\newlabel{fig:SC}{{3}{13}}
\citation{bondanelli2020coding}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}EPI scales well to high-dimensional parameter spaces}{14}}
\newlabel{results_LRRNN}{{3.5}{14}}
\citation{kass2001spike}
\citation{brown1998statistical}
\citation{paninski2004maximum}
\citation{truccolo2005point}
\citation{druckmann2007novel}
\citation{byron2009gaussian}
\citation{park2011bayesian}
\citation{latimer2015single}
\citation{lakshminarasimhan2018dynamic}
\citation{duncker2019learning}
\citation{ladenbauer2019inferring}
\citation{paninski2018neural}
\newlabel{eq:SNPE_stab_amp_x0}{{14}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {A}. Recurrent neural network. \textbf  {B}. EPI scales with $z$ to high dimensions. Convergence definitions: EPI (blue) - satisfies all moment constraints, SNPE (orange)- produces at least 2/$n_{\text  {train}}$ parameter samples are in the bounds of emergent property (mean +- 0.5), and SMC-ABC (red) - 100 particles with $\epsilon < 0.5$ are produced. \textbf  {C}. Posterior predictive distributions of EPI (blue), SNPE (orange), and SMC-ABC (red). Gray star indicates emergent property mean, and gray dashed lines indicate two standard deviations corresponding to the variance constraint. For $N <= 6$ where SMC-ABC converges, samples are not diverse (path degeneracies). For $N >= 25$, SNPE does not produce a posterior approximation yielding parameters with simulations near $x_0$. \textbf  {D}. Simulations of network parameters resulting from each method ($\tau =100ms$). Each trace corresponds to simulation of one $z$. \textbf  {E}. Ratio of obtained samples producing stable amplification. }}{16}}
\newlabel{fig:LRRNN}{{4}{16}}
\citation{kraynyukova2018stabilized}
\citation{morrison2016diversity}
\citation{litwin2016inhibitory}
\citation{GarciaDelMolino2017}
\citation{Chen2019}
\citation{pitkow2017inference}
\citation{echeveste2019cortical}
\citation{mastrogiuseppe2018linking}
\citation{richards2019deep}
\bibdata{eLife2020}
\bibcite{abbott2008theoretical}{1}
\bibcite{hopfield1982neural}{2}
\bibcite{sompolinsky1988chaos}{3}
\bibcite{tsodyks1997paradoxical}{4}
\bibcite{wong2006recurrent}{5}
\bibcite{foster1993significance}{6}
\bibcite{prinz2004similar}{7}
\bibcite{achard2006complex}{8}
\bibcite{o2014cell}{9}
\bibcite{alonso2019visualization}{10}
\bibcite{kass2001spike}{11}
\bibcite{brown1998statistical}{12}
\bibcite{paninski2004maximum}{13}
\bibcite{truccolo2005point}{14}
\bibcite{schneidman2006weak}{15}
\bibcite{druckmann2007novel}{16}
\bibcite{turner2007maximum}{17}
\bibcite{byron2009gaussian}{18}
\bibcite{macke2011empirical}{19}
\bibcite{park2011bayesian}{20}
\bibcite{latimer2015single}{21}
\bibcite{lakshminarasimhan2018dynamic}{22}
\bibcite{duncker2019learning}{23}
\bibcite{ladenbauer2019inferring}{24}
\bibcite{paninski2018neural}{25}
\bibcite{sisson2007sequential}{26}
\bibcite{liepe2014framework}{27}
\bibcite{kingma2013auto}{28}
\bibcite{rezende2014stochastic}{29}
\bibcite{gao2016linear}{30}
\bibcite{zhao2017recursive}{31}
\bibcite{barello2018sparse}{32}
\bibcite{pandarinath2018inferring}{33}
\bibcite{wiltschko2015mapping}{34}
\bibcite{johnson2016composing}{35}
\bibcite{batty2019behavenet}{36}
\bibcite{gelman2013philosophy}{37}
\bibcite{blei2014build}{38}
\bibcite{transtrum2015perspective}{39}
\bibcite{tran2017hierarchical}{40}
\bibcite{rezende2015variational}{41}
\bibcite{dinh2016density}{42}
\bibcite{papamakarios2017masked}{43}
\bibcite{loaiza2017maximum}{44}
\bibcite{goldman2001global}{45}
\bibcite{litwin2016inhibitory}{46}
\bibcite{duan2018collicular}{47}
\bibcite{marder2002cellular}{48}
\bibcite{gutierrez2013multiple}{49}
\bibcite{jaynes1957information}{50}
\bibcite{elsayed2017structure}{51}
\bibcite{savin2017maximum}{52}
\bibcite{goldman2009memory}{53}
\bibcite{murphy2009balanced}{54}
\bibcite{ozeki2009inhibitory}{55}
\bibcite{rubin2015stabilized}{56}
\bibcite{markram2004interneurons}{57}
\bibcite{rudy2011three}{58}
\bibcite{tremblay2016}{59}
\bibcite{pfeffer2013inhibition}{60}
\bibcite{GarciaDelMolino2017}{61}
\bibcite{Chen2019}{62}
\bibcite{hennequin2018dynamical}{63}
\bibcite{palmigiano2020structure}{64}
\bibcite{duan2015requirement}{65}
\bibcite{kraynyukova2018stabilized}{66}
\bibcite{morrison2016diversity}{67}
\bibcite{pitkow2017inference}{68}
\bibcite{echeveste2019cortical}{69}
\bibcite{mastrogiuseppe2018linking}{70}
\bibcite{richards2019deep}{71}
\bibcite{karlsson2012efficient}{72}
\bibcite{chen2018neural}{73}
\bibcite{li2020scalable}{74}
\bibcite{raue2009structural}{75}
\bibcite{raman2017delineating}{76}
\bibcite{saccomani2003parameter}{77}
\bibcite{kingma2014adam}{78}
\bibcite{wainwright2008graphical}{79}
\bibcite{blei2017variational}{80}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Emergent property inference (EPI)}{26}}
\newlabel{methods_EPI}{{5.1}{26}}
\citation{jaynes1957information}
\citation{elsayed2017structure}
\citation{loaiza2017maximum}
\citation{richards2019deep}
\citation{karlsson2012efficient}
\citation{chen2018neural}
\citation{li2020scalable}
\citation{raue2009structural}
\citation{raman2017delineating}
\citation{saccomani2003parameter}
\newlabel{eq:opt}{{17}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Related approaches}{27}}
\newlabel{methods_related}{{5.1.1}{27}}
\citation{rezende2015variational}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Normalizing flows}{28}}
\newlabel{methods_NF}{{5.1.2}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Augmented Lagrangian optimization}{28}}
\newlabel{methods_AL_opt}{{5.1.3}{28}}
\citation{kingma2014adam}
\newlabel{eq:AL}{{21}{29}}
\citation{wainwright2008graphical}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Example: 2D LDS}{31}}
\newlabel{methods_2DLDS}{{5.1.4}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS1): A. Two-dimensional linear dynamical system model, where real entries of the dynamics matrix $A$ are the parameters. B. The EPI distribution for a two-dimensional linear dynamical system with $\tau =1$ that produces an average of 1Hz oscillations with some small amount of variance. Dashed lines indicate the parameter axes. C. Entropy throughout the optimization. At the beginning of each augmented Lagrangian epoch (2,000 iterations), the entropy dipped due to the shifted optimization manifold where emergent property constraint satisfaction is increasingly weighted. D. Emergent property moments throughout optimization. At the beginning of each augmented Lagrangian epoch, the emergent property moments adjust closer to their constraints.}}{32}}
\newlabel{fig:LDS1}{{5.1.4}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS2): A. Probability contours in the $a_1$-$a_4$ plane were derived from the relationship to emergent property statistic of growth/decay factor $\text  {real}(\lambda _1)$. B. Probability contours in the $a_2$-$a_3$ plane were derived from the emergent property statistic of oscillation frequency $2\pi \text  {imag}(\lambda _1)$.}}{33}}
\newlabel{fig:LDS2}{{5.1.4}{33}}
\citation{wainwright2008graphical}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS3): Sampled dynamical systems $\mathbf  {z} \sim q_{\bm  {\theta }}(\mathbf  {z})$ and their simulated activity from $\mathbf  {x}(0) = [\frac  {\sqrt  {2}}{2}, -\frac  {\sqrt  {2}}{2}]$ colored by log probability. A. Each dimension of the simulated trajectories throughout time. B The simulated trajectories in phase space.}}{34}}
\newlabel{fig:LDS3}{{5.1.4}{34}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}Maximum entropy distributions and exponential families}{34}}
\newlabel{methods_ME_EF}{{5.1.5}{34}}
\newlabel{eq:max_ent}{{28}{34}}
\citation{blei2017variational}
\newlabel{eq:moments}{{32}{35}}
\newlabel{eq:mu_opt}{{33}{35}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.6}EPI as variational inference}{35}}
\newlabel{methods_VI}{{5.1.6}{35}}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Theoretical models}{37}}
\newlabel{methods_theoretical_models}{{5.2}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Stomatogastric ganglion}{37}}
\newlabel{methods_STG}{{5.2.1}{37}}
\citation{palmigiano2020structure}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (STG1): EPI optimization of the STG model producing network syncing. A. Entropy throughout optimization. B. The emergent property statistic means and variances converge to their constraints at 25,000 iterations following the fifth augmented Lagrangian epoch.}}{40}}
\newlabel{fig:STG1}{{5.2.1}{40}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Primary visual cortex}{40}}
\newlabel{methods_V1}{{5.2.2}{40}}
\citation{duan2018collicular}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Supplemental Figure: (Left) Simulations for small increases in neuron-type population input. Input magnitudes are chosen so that effect is salient ($0.002$ for E and P, but $0.02$ for S and V). (Right) Average and standard deviation of stochastic fluctuations of responses. }}{42}}
\newlabel{fig:V1_1}{{9}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Superior colliculus}{42}}
\newlabel{methods_SC}{{5.2.3}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Supplemental Figure: Fano factors along the ridge of the posterior in Fig. 2\hbox {}E. }}{43}}
\newlabel{fig:V1_2}{{10}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Rank-2 RNN}{45}}
\newlabel{methods_RNN}{{5.2.4}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC1): Connectivity parameters of EPI distributions versus task accuracies. $\beta $ is slope coefficient of linear regression, $r$ is correlation, and $p$ is the two-tailed p value. }}{46}}
\newlabel{fig:SC1}{{11}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC2): A. Invariant eigenvectors of connectivity matrix $W$. B. Eigenvalues of connectivities of EPI distribution versus task accuracies.}}{47}}
\newlabel{fig:SC2}{{12}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC3): A. Connectitivy eigenvalues of EPI parameter distribution colored by Pro task accuracy. B. Same for Anti task. }}{47}}
\newlabel{fig:SC3}{{13}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC4): Scatters of the effect of delay period inactivation in each task with task accuracy. Plots are shown at an opto strength of 0.8. }}{48}}
\newlabel{fig:SC4}{{14}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC5): EPI optimization of the SC model producing rapid task switching. A. Entropy throughout optimization. B. The emergent property statistic means and variances converge to their constraints at 12,000 iterations following the sixth augmented Lagrangian epoch. }}{48}}
\newlabel{fig:SC5}{{15}{48}}
