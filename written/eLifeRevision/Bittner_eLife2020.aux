\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}}
\citation{kopell1988coupled,marder1998biophysics,abbott2008theoretical,wang2010neurophysiological,o2015computational}
\citation{gutenkunst2007universally,erguler2011practical,mannakee2016sloppiness}
\citation{hopfield1982neural}
\citation{sompolinsky1988chaos}
\citation{olypher2007using}
\citation{tsodyks1997paradoxical}
\citation{wong2006recurrent}
\citation{foster1993significance,prinz2004similar,achard2006complex,fisher2013modeling,o2014cell,alonso2019visualization}
\citation{paninski2018neural}
\citation{niell2010modulation,saleem2013integration,musall2019single}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{2}}
\citation{beaumont2002approximate,marjoram2003markov,sisson2007sequential}
\citation{raue2009structural,karlsson2012efficient,hines2014determination,raman2017delineating}
\citation{elsayed2017structure,savin2017maximum,mlynarski2020statistical}
\citation{tran2017hierarchical,gonccalves2019training}
\citation{loaiza2017maximum}
\citation{dinh2017density,kingma2018glow}
\citation{gutierrez2013multiple}
\citation{goldman2001global}
\citation{murphy2009balanced,hennequin2014optimal,bondanelli2019population}
\citation{litwin2016inhibitory,palmigiano2020structure}
\citation{duan2018collicular}
\citation{marder2002cellular}
\citation{goldman2001global,prinz2004similar}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivating emergent property inference of theoretical models}{4}}
\newlabel{results_motivating}{{3.1}{4}}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}A deep generative modeling approach to emergent property inference}{5}}
\newlabel{results_dgm}{{3.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Emergent property inference (EPI) in the stomatogastric ganglion. \textbf  {A}. Conductance-based subcircuit model of the STG. \textbf  {B}. Spiking frequency $\omega (\mathbf  {x}; \mathbf  {z})$ is an emergent property statistic. Simulated at $g_{\text  {el}} = 4.5$nS and $g_{\text  {synA}} = 3$nS. \textbf  {C}. The emergent property of intermediate hub frequency. Simulated activity traces are colored by $\qopname  \relax o{log}q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X})$ of generating parameters. (Panel E). \textbf  {D}. For a choice of circuit model and emergent property, emergent property inference (EPI) learns a deep probability distribution of parameters $\mathbf  {z}$. \textbf  {E}. The EPI distribution producing intermediate hub frequency. Samples are colored by log probability density. Contours of hub neuron frequency error are shown at levels of $.525$, $.53$, ... $.575$ Hz (dark to light gray away from mean). Dimension of sensitivity $\mathbf  {v}_1$ (solid) and robustness $\mathbf  {v}_2$ (dashed). \textbf  {F} (Top) The predictive distribution of EPI. The black and gray dashed lines show the mean and two standard deviations according the emergent property. (Bottom) Simulations at the starred parameter values. }}{6}}
\newlabel{fig:STG}{{1}{6}}
\citation{rezende2015variational,dinh2017density,papamakarios2017masked}
\newlabel{eq:EP_STG}{{4}{7}}
\citation{litwin2016inhibitory,palmigiano2020structure}
\citation{duan2018collicular}
\citation{murphy2009balanced,hennequin2014optimal,bondanelli2019population}
\citation{goldman2009memory,murphy2009balanced}
\citation{bondanelli2020coding}
\citation{sussillo2014neural,barak2017recurrent}
\citation{sompolinsky1988chaos}
\citation{russo2018motor}
\citation{bondanelli2020coding}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Scaling inference of RNN connectivity with EPI}{8}}
\newlabel{results_RNN}{{3.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {A}. Wall time of EPI (blue), SNPE (orange), and SMC-ABC (green) to converge on RNN connectivities producing stable amplification. Each dot shows convergence time for an individual random seed. For reference, the mean wall time for EPI to achieve its full constraint convergence (means and variances) is shown (blue line). \textbf  {B}. Simulation count of each algorithm to achieve convergence. Same conventions as A. \textbf  {C}. The predictive distributions of connectivities inferred by EPI (blue), SNPE (orange), and SMC-ABC (green), with reference to $\mathbf  {x}_0 = \bm  {\mu }$ (gray star). \textbf  {D}. Simulations of networks inferred by each method ($\tau =100ms$). Each trace (15 per algorithm) corresponds to simulation of one $z$. (Below) Ratio of obtained samples producing stable amplification, monotonic decay, and instability. }}{9}}
\newlabel{fig:RNN}{{2}{9}}
\citation{sisson2007sequential}
\citation{gonccalves2019training}
\citation{sisson2018handbook}
\newlabel{eq:EP_LRRNN}{{6}{10}}
\citation{cranmer2020frontier}
\citation{marder1992dynamic}
\citation{prinz2004similar}
\citation{gonccalves2019training}
\citation{tsodyks1997paradoxical}
\citation{goldman2009memory,murphy2009balanced}
\citation{ozeki2009inhibitory}
\citation{rubin2015stabilized}
\citation{hennequin2018dynamical}
\citation{Churchland2010}
\citation{semedo2019cortical}
\citation{markram2004interneurons,rudy2011three,tremblay2016}
\citation{pfeffer2013inhibition}
\citation{felleman1991distributed}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}EPI reveals how recurrence with multiple inhibitory subtypes governs excitatory variability in a V1 model}{11}}
\newlabel{results_V1}{{3.4}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Emergent property inference in the stochastic stabilized supralinear network (SSSN) \textbf  {A}. Four-population model of primary visual cortex with excitatory (black), parvalbumin (blue), somatostatin (red), and VIP (green) neurons (excitatory and inhibitory projections filled and unfilled, respectively). Some neuron-types largely do not form synaptic projections to others ($|W_{\alpha _1, \alpha _2})| < 0.025$). Each neural population receives a baseline input $\mathbf  {h}_b$, and the E- and P-populations also receive a contrast-dependent input $\mathbf  {h}_c$. Additionally, each neural population receives a slow noisy input $\bm  {\epsilon }$. \textbf  {B}. Transient network responses of the SSSN model. Traces are independent trials with varying initialization $\mathbf  {x}(0)$ and noise $\bm  {\epsilon }$. \textbf  {C}. Mean (solid line) and standard deviation $s_E(\mathbf  {x}; \mathbf  {z})$ (shading) across 100 trials. \textbf  {D}. EPI distribution of noise parameters $\mathbf  {z}$ conditioned on E-population variability. The EPI predictive distribution of $s_E(\mathbf  {x}; \mathbf  {z})$ is show on the bottom-left. \textbf  {E}. (Top) Enlarged visualization of the $\sigma _E$-$\sigma _P$ marginal distribution of EPI $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X}(5\text  { Hz})$ and $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X}(10\text  { Hz})$. Each black dot shows the mode at each $\sigma _P$. The arrows show the most sensitive dimensions of the Hessian evaluated at these modes. \textbf  {F}. The predictive distributions of $\sigma _E^2 + \sigma _P^2$ of each inferred distribution $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X}(5\text  { Hz})$ and $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X}(10\text  { Hz})$. }}{12}}
\newlabel{fig:V1}{{3}{12}}
\citation{hennequin2018dynamical}
\citation{litwin2016inhibitory}
\citation{palmigiano2020structure}
\newlabel{eq:EP_V1}{{8}{13}}
\citation{hennequin2018dynamical,Gardiner2009}
\citation{duan2015requirement}
\citation{duan2018collicular}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}EPI identifies two regimes of rapid task switching}{14}}
\newlabel{results_SC}{{3.5}{14}}
\newlabel{eq:SC_EP}{{10}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \textbf  {A}. Rapid task switching behavioral paradigm (see text). \textbf  {B}. Model of superior colliculus (SC). Neurons: LP - Left Pro, RP - Right Pro, LA - Left Anti, RA - Right Anti. Parameters: $sW$ - self, $hW$ - horizontal, $vW$ -vertical, $dW$ - diagonal weights. \textbf  {C}. The EPI inferred distribution of rapid task switching networks. Stars indicate modes $\mathbf  {z}^*$ whose color indicates connectivity regime (see legend Fig 4\hbox {}D). Sensitivity vectors $\mathbf  {v}_1(\mathbf  {z}^*)$ are shown by arrows. (Bottom-left) EPI predictive distribution of task accuracies. \textbf  {D}. The connectivity regimes have different responses to perturbation. (Top) Mean and standard error ($N_{\text  {test}}$ = 25) of accuracy with respect to perturbation along the sensitivity dimension of each mode $\mathbf  {z}^*$. (Middle) Same with perturbation in the dimension of increasing $\lambda _{\text  {task}}$ ($\mathbf  {v}_{\text  {task}}$). (Bottom) Same with perturbation in the dimension of increasing $\lambda _{\text  {diag}}$ ($\mathbf  {v}_{\text  {diag}}$). }}{16}}
\newlabel{fig:SC}{{4}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}EPI inferred SC connectivities reproduce results from optogenetic inactivation experiments}{18}}
\newlabel{results_SC_opt}{{3.6}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \textbf  {A}. Experimental effect of delay period silencing on Pro and Anti task accuracy in rats. \textbf  {B}. Mean and standard error (bars) of task error induced by delay period inactivation of varying optogenetic strength across the EPI distribution. \textbf  {C}. (Left) Mean and standard error of Pro and Anti error from regime 1 to regime 2 at $\gamma = 0.675$. (Right) Correlations of connectivity eigenvalues with Anti error from regime 1 to regime 2 at $\gamma = 0.675$. \textbf  {D}. (Left) Mean and standard deviation (shading) of responses of the SC model at the mode of the EPI distribution to delay period inactivation at $\gamma = 0.85$. (Right) Anti accuracy following delay period inactivation at $\gamma = 0.85$ versus accuracy in the Pro task across connectivities in the EPI distribution. }}{19}}
\newlabel{fig:SC_opto}{{5}{19}}
\citation{paninski2018neural}
\citation{beaumont2002approximate,marjoram2003markov,sisson2007sequential}
\citation{gonccalves2019training}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{20}}
\citation{gonccalves2019training}
\citation{saccomani2003parameter,raue2009structural,karlsson2012efficient,raman2017delineating}
\bibdata{eLife2020}
\bibcite{kopell1988coupled}{1}
\bibcite{marder1998biophysics}{2}
\bibcite{abbott2008theoretical}{3}
\bibcite{wang2010neurophysiological}{4}
\bibcite{o2015computational}{5}
\bibcite{gutenkunst2007universally}{6}
\bibcite{erguler2011practical}{7}
\bibcite{mannakee2016sloppiness}{8}
\bibcite{hopfield1982neural}{9}
\bibcite{sompolinsky1988chaos}{10}
\bibcite{olypher2007using}{11}
\bibcite{tsodyks1997paradoxical}{12}
\bibcite{wong2006recurrent}{13}
\bibcite{foster1993significance}{14}
\bibcite{prinz2004similar}{15}
\bibcite{achard2006complex}{16}
\bibcite{fisher2013modeling}{17}
\bibcite{o2014cell}{18}
\bibcite{alonso2019visualization}{19}
\bibcite{paninski2018neural}{20}
\bibcite{niell2010modulation}{21}
\bibcite{saleem2013integration}{22}
\bibcite{musall2019single}{23}
\bibcite{beaumont2002approximate}{24}
\bibcite{marjoram2003markov}{25}
\bibcite{sisson2007sequential}{26}
\bibcite{raue2009structural}{27}
\bibcite{karlsson2012efficient}{28}
\bibcite{hines2014determination}{29}
\bibcite{raman2017delineating}{30}
\bibcite{elsayed2017structure}{31}
\bibcite{savin2017maximum}{32}
\bibcite{mlynarski2020statistical}{33}
\bibcite{tran2017hierarchical}{34}
\bibcite{gonccalves2019training}{35}
\bibcite{loaiza2017maximum}{36}
\bibcite{dinh2017density}{37}
\bibcite{kingma2018glow}{38}
\bibcite{gutierrez2013multiple}{39}
\bibcite{goldman2001global}{40}
\bibcite{murphy2009balanced}{41}
\bibcite{hennequin2014optimal}{42}
\bibcite{bondanelli2019population}{43}
\bibcite{litwin2016inhibitory}{44}
\bibcite{palmigiano2020structure}{45}
\bibcite{duan2018collicular}{46}
\bibcite{marder2002cellular}{47}
\bibcite{rezende2015variational}{48}
\bibcite{papamakarios2017masked}{49}
\bibcite{goldman2009memory}{50}
\bibcite{bondanelli2020coding}{51}
\bibcite{sussillo2014neural}{52}
\bibcite{barak2017recurrent}{53}
\bibcite{russo2018motor}{54}
\bibcite{sisson2018handbook}{55}
\bibcite{cranmer2020frontier}{56}
\bibcite{marder1992dynamic}{57}
\bibcite{ozeki2009inhibitory}{58}
\bibcite{rubin2015stabilized}{59}
\bibcite{hennequin2018dynamical}{60}
\bibcite{Churchland2010}{61}
\bibcite{semedo2019cortical}{62}
\bibcite{markram2004interneurons}{63}
\bibcite{rudy2011three}{64}
\bibcite{tremblay2016}{65}
\bibcite{pfeffer2013inhibition}{66}
\bibcite{felleman1991distributed}{67}
\bibcite{Gardiner2009}{68}
\bibcite{duan2015requirement}{69}
\bibcite{saccomani2003parameter}{70}
\bibcite{saul1998mean}{71}
\bibcite{metropolis1953equation}{72}
\bibcite{hastings1970monte}{73}
\bibcite{girolami2011riemann}{74}
\bibcite{golightly2011bayesian}{75}
\bibcite{bittner2019degenerate}{76}
\bibcite{bittner2019examining}{77}
\bibcite{nonnenmacher2018sbi}{78}
\bibcite{desitler2019statistical}{79}
\bibcite{LueckmannGoncalves_17}{80}
\bibcite{papamakarios2019sequential}{81}
\bibcite{hermans2020likelihood}{82}
\bibcite{wainwright2008graphical}{83}
\bibcite{bittner2019approximating}{84}
\bibcite{chen2018neural}{85}
\bibcite{li2020scalable}{86}
\bibcite{papamakarios2019normalizing}{87}
\bibcite{kingma2016improved}{88}
\bibcite{kingma2014adam}{89}
\bibcite{klinger2018pyabc}{90}
\bibcite{greenberg2019automatic}{91}
\bibcite{Mossing2021}{92}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Emergent property inference (EPI)}{31}}
\newlabel{methods_EPI}{{5.1}{31}}
\newlabel{eq:methods_ep_general}{{11}{31}}
\citation{loaiza2017maximum}
\citation{saul1998mean}
\citation{metropolis1953equation,hastings1970monte}
\citation{girolami2011riemann}
\citation{golightly2011bayesian}
\newlabel{eq:deep_transform}{{12}{32}}
\newlabel{eq:opt}{{13}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Related approaches}{32}}
\newlabel{methods_related}{{5.1.1}{32}}
\citation{cranmer2020frontier}
\citation{beaumont2002approximate}
\citation{marjoram2003markov}
\citation{sisson2007sequential}
\citation{saul1998mean}
\citation{loaiza2017maximum}
\citation{tran2017hierarchical}
\citation{bittner2019degenerate,bittner2019examining}
\citation{nonnenmacher2018sbi,desitler2019statistical,gonccalves2019training}
\citation{loaiza2017maximum}
\citation{LueckmannGoncalves_17}
\citation{papamakarios2019sequential}
\citation{hermans2020likelihood}
\citation{wainwright2008graphical}
\citation{bittner2019approximating}
\citation{karlsson2012efficient}
\citation{chen2018neural}
\citation{li2020scalable}
\citation{raue2009structural}
\citation{raman2017delineating}
\citation{saccomani2003parameter}
\citation{rezende2015variational,papamakarios2019normalizing}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Deep probability distributions and normalizing flows}{35}}
\newlabel{methods_NF}{{5.1.2}{35}}
\citation{dinh2017density}
\citation{kingma2018glow}
\citation{papamakarios2017masked,kingma2016improved}
\citation{kingma2016improved,papamakarios2017masked}
\citation{wainwright2008graphical}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Maximum entropy distributions and exponential families}{36}}
\newlabel{methods_ME_EF}{{5.1.3}{36}}
\newlabel{eq:max_ent}{{15}{36}}
\citation{kingma2014adam}
\newlabel{eq:moments}{{18}{37}}
\newlabel{eq:mu_opt}{{19}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Augmented Lagrangian optimization}{37}}
\newlabel{methods_AL_opt}{{5.1.4}{37}}
\newlabel{eq:AL}{{20}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}Example: 2D LDS}{39}}
\newlabel{methods_2DLDS}{{5.1.5}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS1): \textbf  {A}. Two-dimensional linear dynamical system model, where real entries of the dynamics matrix $A$ are the parameters. \textbf  {B}. The EPI distribution for a two-dimensional linear dynamical system with $\tau =1$ that produces an average of 1Hz oscillations with some small amount of variance. Dashed lines indicate the parameter axes. \textbf  {C}. Entropy throughout the optimization. At the beginning of each augmented Lagrangian epoch (2,000 iterations), the entropy dipped due to the shifted optimization manifold where emergent property constraint satisfaction is increasingly weighted. \textbf  {D}. Emergent property moments throughout optimization. At the beginning of each augmented Lagrangian epoch, the emergent property moments adjust closer to their constraints.}}{40}}
\newlabel{fig:LDS1}{{6}{40}}
\citation{wainwright2008graphical}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS2): \textbf  {A}. Probability contours in the $a_1$-$a_4$ plane were derived from the relationship to emergent property statistic of growth/decay factor $\text  {real}(\lambda _1)$. \textbf  {B}. Probability contours in the $a_2$-$a_3$ plane were derived from the emergent property statistic of oscillation frequency $2\pi \text  {imag}(\lambda _1)$.}}{41}}
\newlabel{fig:LDS2}{{7}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS3): Sampled dynamical systems $\mathbf  {z} \sim q_{\bm  {\theta }}(\mathbf  {z})$ and their simulated activity from $\mathbf  {x}(0) = [\frac  {\sqrt  {2}}{2}, -\frac  {\sqrt  {2}}{2}]$ colored by log probability. \textbf  {A}. Each dimension of the simulated trajectories throughout time. \textbf  {B}. The simulated trajectories in phase space.}}{42}}
\newlabel{fig:LDS3}{{5.1.5}{42}}
\citation{saul1998mean}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.6}EPI as variational inference}{43}}
\newlabel{methods_VI}{{5.1.6}{43}}
\newlabel{eq:eta_f}{{36}{43}}
\citation{gutierrez2013multiple}
\citation{gutierrez2013multiple}
\citation{marder1992dynamic}
\citation{prinz2004similar,gonccalves2019training}
\newlabel{eq:VI_obj}{{38}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Stomatogastric ganglion}{44}}
\newlabel{methods_STG}{{5.2}{44}}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}STG model}{45}}
\newlabel{methods_stg_model}{{5.2.1}{45}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Hub frequency calculation}{46}}
\newlabel{methods_stg_hub}{{5.2.2}{46}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}EPI details for the STG model}{47}}
\newlabel{methods_stg_epi}{{5.2.3}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (STG1): EPI optimization of the STG model producing network syncing. \textbf  {A}. Entropy throughout optimization. \textbf  {B}. The emergent property statistic means and variances converge to their constraints at 25,000 iterations following the fifth augmented Lagrangian epoch.}}{48}}
\newlabel{fig:STG1}{{5.2.3}{48}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Hessian sensitivity vectors}{48}}
\newlabel{methods_stg_hessian}{{5.2.4}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Scaling EPI for stable amplification in RNNs}{48}}
\newlabel{methods_RNN}{{5.3}{48}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Rank-2 RNN model}{48}}
\citation{sisson2007sequential}
\citation{gonccalves2019training}
\citation{bondanelli2020coding}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Stable amplification}{49}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}EPI details for RNNs}{49}}
\citation{beaumont2002approximate}
\citation{klinger2018pyabc}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (RNN1): Number of parameters in deep probability distribution architectures of EPI (blue) and SNPE (orange) by RNN size ($N$). }}{50}}
\newlabel{fig:RNN1}{{10}{50}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Methodological comparison}{50}}
\newlabel{eq:stab_amp_x0}{{64}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (RNN2): Model characteristics affect predictions of posteriors inferred by SNPE, while predictions of parameters inferred by EPI remain fixed. \textbf  {A}. Predictive distribution of EPI (blue) and SNPE (orange) inferred connectivity of RNNs exhibiting stable amplification with $N=2$ (top), $N=10$ (bottom), $g=0.01$ (left), and $g=0.1$ (right). \textbf  {B}. Entropy of parameter distribution approximations throughout optimization with $N=2$ (top), $N=10$ (bottom), $g=0.1$ (dark shade), and $g=0.01$ (light shade). \textbf  {C}. Validation log probabilities throughout SNPE optimization. Same conventions as B. \textbf  {D}. Adherence to EPI constraints. Same conventions as B. }}{52}}
\newlabel{fig:RNN2}{{11}{52}}
\citation{greenberg2019automatic}
\citation{greenberg2019automatic}
\citation{tremblay2016}
\citation{markram2004interneurons,rudy2011three,tremblay2016}
\citation{pfeffer2013inhibition}
\citation{Mossing2021,palmigiano2020structure}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Primary visual cortex}{53}}
\newlabel{methods_V1}{{5.4}{53}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}V1 model}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (RNN3): SNPE convergence was enabled by increasing $n_{\text  {round}}$, not $n_{\text  {atom}}$. \textbf  {A}. Difference of mean predictions $\mathbf  {x}_0$ throughout optimization at $N=50$ with by simulation count (left) and wall time (right) of SNPE with $n_{\text  {round}} = 5,000$ (light orange), SNPE with $n_{\text  {round}} = 25,000$ (dark orange), and EPI (blue). Each line shows an individual random seed. \textbf  {B}. Same conventions as A at $N=100$ of SNPE with $n_{\text  {atom}} = 100$ (light orange) and $n_{\text  {atom}} = 1,000$ (dark orange). \textbf  {C}. Same conventions as A at $N=100$ of SNPE with $n_{\text  {round}} = 25,000$ (light orange) and $n_{\text  {round}} = 250,000$ (dark orange). }}{54}}
\newlabel{fig:RNN3}{{12}{54}}
\citation{hennequin2018dynamical}
\citation{palmigiano2020structure}
\newlabel{sigma_reparam}{{68}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (V1 1) (Left) Simulations for small increases in neuron-type population input. Input magnitudes are chosen so that effect is salient ($0.002$ for E and P, but $0.02$ for S and V). (Right) Average (solid) and standard deviation (shaded) of stochastic fluctuations of responses. }}{56}}
\newlabel{fig:V1_1}{{13}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (V1 2) EPI predictive distributions of the sum of squares of each pair of noise parameters. }}{57}}
\newlabel{fig:V1_2}{{14}{57}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (V1 3) EPI inferred distribution for $\mathcal  {X}(10\text  { Hz})$. }}{58}}
\newlabel{fig:V1_3}{{15}{58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}EPI details for the V1 model}{58}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}Sensitivity analyses}{59}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (V1 4) Optimization for V1 }}{59}}
\newlabel{fig:V1_4}{{16}{59}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.4}Primary visual cortex: Mathematical intuition and challenges}{59}}
\newlabel{methods_V1_complexity}{{5.4.4}{59}}
\newlabel{SSSN_agos}{{77}{59}}
\citation{hennequin2018dynamical,Gardiner2009}
\citation{Gardiner2009}
\newlabel{GeneralEllipsoid}{{82}{60}}
\citation{duan2015requirement}
\citation{duan2018collicular}
\citation{duan2018collicular}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Superior colliculus}{61}}
\newlabel{methods_SC}{{5.5}{61}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}SC model}{61}}
\newlabel{methods_sc_model}{{5.5.1}{61}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC1): \textbf  {A}. Same pairplot as Fig. 4\hbox {}C colored by Pro task accuracy. \textbf  {B}. Same as A colored by Anti task accuracy. \textbf  {C}. Connectivity parameters of EPI distributions versus task accuracies. $\beta $ is slope coefficient of linear regression, $r$ is correlation, and $p$ is the two-tailed p-value. }}{62}}
\newlabel{fig:SC1}{{17}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC2): \textbf  {A}. Simulations in network regime 1 ($hW_{\text  {fixed}} = -1.5$). \textbf  {B}. Simulations in network regime 2 ($hW_{\text  {fixed}} = -1.5$) . }}{63}}
\newlabel{fig:SC2}{{18}{63}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC3): \textbf  {A}. Invariant eigenvectors of connectivity matrix $W$. \textbf  {B}. Accuracies for connectivity perturbations for increasing $\lambda _{\text  {all}}$ and $\lambda _{\text  {side}}$ (rest shown in Fig. 4\hbox {}D). }}{64}}
\newlabel{fig:SC3}{{19}{64}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Task accuracy calculation}{64}}
\newlabel{methods_sc_acc}{{5.5.2}{64}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC4): \textbf  {A}. The individual parameters of each mode throughout the two regimes. \textbf  {B}. The individual sensitivities of parameters of each mode throughout the two regimes. }}{65}}
\newlabel{fig:SC4}{{20}{65}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3}EPI details for the SC model}{65}}
\newlabel{methods_sc_epi}{{5.5.3}{65}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC5): (Left) Mean and standard error of Pro and Anti error from regime 1 to regime 2 at $\gamma = 0.85$. (Right) Correlations of connectivity eigenvalues with Anti error from regime 1 to regime 2 at $\gamma = 0.85$. }}{66}}
\newlabel{fig:SC5}{{21}{66}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC6): (Left) Mean and standard deviation (shading) of responses of the SC model at the mode of the EPI distribution to delay period inactivation at $\gamma = 0.675$. (Right) Anti accuracy following delay period inactivation at $\gamma = 0.675$ versus accuracy in the Pro task across connectivities in the EPI distribution. }}{66}}
\newlabel{fig:SC6}{{22}{66}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC7): \textbf  {A}. Entropy throughout optimization. \textbf  {B}. The emergent property statistic means and variances converge to their constraints at 20,000 iterations following the tenth augmented Lagrangian epoch. }}{67}}
\newlabel{fig:SC7}{{23}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC8): \textbf  {A}. Entropy throughout optimization. \textbf  {B}. The emergent property statistic means and variances converge to their constraints at 20,000 iterations following the tenth augmented Lagrangian epoch. }}{68}}
\newlabel{fig:SC8}{{24}{68}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.4}Regime identification with EPI}{68}}
\newlabel{methods_sc_regime}{{5.5.4}{68}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.5}Sensitivity analysis}{69}}
\newlabel{methods_sc_hessian}{{5.5.5}{69}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.6}Connectivity eigendecomposition and processing modes}{69}}
\newlabel{methods_sc_eig}{{5.5.6}{69}}
\citation{duan2015requirement}
\newlabel{eq:dzdlambda}{{102}{70}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.7}Modeling optogenetic silencing.}{70}}
\newlabel{methods_sc_opto}{{5.5.7}{70}}
