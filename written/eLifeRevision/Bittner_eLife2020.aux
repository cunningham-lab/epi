\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}}
\citation{abbott2008theoretical}
\citation{hopfield1982neural}
\citation{sompolinsky1988chaos}
\citation{tsodyks1997paradoxical}
\citation{wong2006recurrent}
\citation{liepe2014framework}
\citation{kingma2013auto}
\citation{rezende2014stochastic}
\citation{gao2016linear}
\citation{zhao2017recursive}
\citation{barello2018sparse}
\citation{pandarinath2018inferring}
\citation{wiltschko2015mapping}
\citation{johnson2016composing}
\citation{batty2019behavenet}
\citation{paninski2018neural}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{2}}
\citation{raue2009structural}
\citation{gelman2013philosophy}
\citation{blei2014build}
\citation{transtrum2015perspective}
\citation{tran2017hierarchical}
\citation{rezende2015variational}
\citation{dinh2016density}
\citation{papamakarios2017masked}
\citation{loaiza2017maximum}
\citation{goldman2001global}
\citation{gutierrez2013multiple}
\citation{litwin2016inhibitory}
\citation{duan2018collicular}
\citation{mastrogiuseppe2018linking}
\citation{marder2002cellular}
\citation{goldman2001global}
\citation{prinz2004similar}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Motivating emergent property inference of theoretical models}{4}}
\newlabel{results_motivating}{{3.1}{4}}
\citation{gutierrez2013multiple}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}A deep generative modeling approach to emergent property inference}{5}}
\newlabel{results_dgm}{{3.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Emergent property inference (EPI) in the stomatogastric ganglion. \textbf  {A}. Conductance-based biophysical model of the STG subcircuit. In the STG model, jagged connections indicate electrical coupling having electrical conductance $g_{\text  {el}}$. Other connections in the diagram are inhibitory synaptic projections having strength $g_{\text  {synA}}$ onto the hub neuron, and $g_{\text  {synB}}=5$nS for mutual inhibitory connections. Parameters are represented by the vector $\mathbf  {z}$ and data by the vector $\mathbf  {x}$. \textbf  {B}. Simulated activity form the STG model at $g_{\text  {el}} = 4.5$nS and $g_{\text  {synA}} = 3$nS. \textbf  {C}. The emergent property of unified intermediacy, in which all neurons are firing close to the same intermediate frequency. Simulated activity traces are colored by log probability density of their generating parameters in the EPI-inferred distribution. \textbf  {D}. For a choice of model and emergent property, emergent property inference (EPI) learns a distribution of the model parameters $\mathbf  {z} = \left [g_{\text  {el}}, g_{\text  {synA}} \right ]$ producing middle hub frequency. Deep probability distributions map a simple random variable $\mathbf  {z}_0$ through a deep neural network with weights and biases $\bm  {\theta }$ to parameters $\mathbf  {z} = g_{\bm  {\theta }}(\mathbf  {z}_0)$ distributed as $q_{\bm  {\theta }}(\mathbf  {z} \mid \mathcal  {X})$. \textbf  {E}. The EPI distribution of STG model parameters producing network syncing. Samples are colored by log probability density. Distribution contours of hub neuron frequency from mean of .55 Hz are shown at levels of $.525$, $.53$, ... $.575$ Hz (dark to light gray away from mean). Frequencies are averages over the stochasticity of the model. Eigenvectors of the Hessian at the mode of the inferred distribution are indicated as $\mathbf  {v}_1$ (solid) and $\mathbf  {v}_2$ (dashed) with lengths scaled by the square root of the absolute value of their eigenvalues. Simulated activity is shown for three samples (stars). $v_1$ is sensitive to network syncing ($p<10^{-4}$), while $v_2$ is not ($p=0.67$) (see Section 5.2.1\hbox {}). \textbf  {F} Simulations from parameters in E. (Top) The predictive distribution of the posterior obeys the constraints stipulated by the emergent property. (Bottom) Simulations at the starred parameter values. }}{6}}
\newlabel{fig:STG}{{3.1}{6}}
\citation{rezende2015variational}
\citation{dinh2016density}
\citation{papamakarios2017masked}
\citation{jaynes1957information}
\citation{elsayed2017structure}
\citation{loaiza2017maximum}
\citation{savin2017maximum}
\newlabel{eq:EP_STG}{{2}{7}}
\newlabel{eq:EPI}{{3}{7}}
\citation{tsodyks1997paradoxical}
\citation{murphy2009balanced}
\citation{ozeki2009inhibitory}
\citation{rubin2015stabilized}
\citation{markram2004interneurons}
\citation{rudy2011three}
\citation{tremblay2016}
\citation{pfeffer2013inhibition}
\citation{litwin2016inhibitory}
\citation{GarciaDelMolino2017}
\citation{Chen2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Comprehensive input-responsivity in a nonlinear sensory system}{8}}
\newlabel{results_V1}{{3.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Hypothesis generation through EPI in a V1 model. A. Four-population model of primary visual cortex with excitatory (black), parvalbumin (blue), somatostatin (red), and VIP (green) neurons. Some neuron-types largely do not form synaptic projections to others (excitatory and inhibitory projections filled and unfilled, respectively). B. Linear response predictions become inaccurate with greater input strength. V1 model simulations for input (solid) $h=b$ and (dashed) $h = b + dh$. Stars indicate the linear response prediction. C. EPI distributions on differential input $dh$ conditioned on differential response $\mathcal  {B}(\alpha , y)$. Supporting evidence for the four generated hypotheses are indicated by gray boxes with labels H1, H2, H3, and H4. The linear prediction from two standard deviations away from $y$ (from negative to positive) is overlaid in magenta (very small, near origin). }}{9}}
\newlabel{fig:V1_EPI}{{2}{9}}
\citation{allen2018layer}
\citation{billeh2019systematic}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Confirming EPI generated hypotheses in V1. A. Differential responses $\delta x_E$ by the E-population to changes in individual input $\delta h_\alpha \mathaccentV {hat}05E{u}_\alpha $ away from the mode of the EPI distribution $dh^*$. B-D Same plots for the P-, S-, and V-populations. Labels H1, H2, H3, and H4 indicate which curves confirm which hypotheses.}}{11}}
\newlabel{fig:V1_HT}{{3}{11}}
\citation{duan2015requirement}
\citation{duan2018collicular}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Identifying neural mechanisms of flexible task switching}{12}}
\newlabel{results_SC}{{3.4}{12}}
\newlabel{eq:EP}{{8}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip A. Rapid task switching behavioral paradigm (see text). B. Model of superior colliculus (SC). Neurons: LP - left pro, RP - right pro, LA - left anti, RA - right anti. Parameters: $sW$ - self, $hW$ - horizontal, $vW$ -vertical, $dW$ - diagonal weights. Subscripts $P$ and $A$ of connectivity weights indicate Pro or Anti populations. C. The EPI parameter distribution of rapid task switching networks. Black star indicates parameter choice u=of simulations. D. Simulations of an SC network from the EPI distribution with 75\% accuracy in each task. Top row shows no inactivation during Pro and Anti trials, and bottom row shows simulations with delay period inactivation (opto strength 0.7). Shading indicates standard deviation across trials. E. Difference in performance of each task during inactivation. Inactivation level ``opto strength" scales from no inactivation (0) to full inactivation (1). We compare delay period inactivation $1.2 < t < 1.5$ (blue), choice period inactivation $1.5 < t$ (red), and total inactivation $0 \leq t \leq 1.8$ (purple). F. The effect of delay period inactivation on Anti accuracy versus dynamics eigenvalues. }}{14}}
\newlabel{fig:SC}{{4}{14}}
\citation{barak2017recurrent}
\citation{sussillo2013opening}
\citation{mastrogiuseppe2018linking}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Linking RNN connectivity to error}{15}}
\newlabel{results_RNN}{{3.5}{15}}
\citation{mastrogiuseppe2018linking}
\citation{sompolinsky1988chaos}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip Sources of error in an RNN solving a simple task. A. (left) A rank-1 RNN executing a Gaussian posterior conditioning computation on $\mu _y$. (right) Error in this computation can come from over- or under-estimating the posterior mean or variance. B. EPI distribution of rank-1 RNNs executing Gaussian posterior conditioning. Samples are colored by (left) posterior mean $\mu _{\text  {post}}=\kappa _r$ and (right) posterior variance $\sigma ^2_{\text  {post}}=\Delta _T$ C. Finite-size network simulations of 2,000 neurons with parameters $z_1$ and $z_2$ sampled from the inferred distribution. Activity along readout $\kappa _r$ (cyan) is stable despite chaotic fluctuations. D. The posterior mean computed by RNNs parameterized by $z_1$ and $z_2$ perturbed in the dimension of the product of $M_m$ and $M_n$. Means and standard errors are shown across 10 realizations of 2,000-neuron networks.}}{17}}
\newlabel{fig:RNN}{{5}{17}}
\citation{mastrogiuseppe2018linking}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}EPI is a general tool for theoretical neuroscience}{18}}
\citation{loaiza2017maximum}
\citation{mastrogiuseppe2018linking}
\citation{kass2001spike}
\citation{brown1998statistical}
\citation{paninski2004maximum}
\citation{truccolo2005point}
\citation{druckmann2007novel}
\citation{byron2009gaussian}
\citation{park2011bayesian}
\citation{latimer2015single}
\citation{lakshminarasimhan2018dynamic}
\citation{duncker2019learning}
\citation{ladenbauer2019inferring}
\citation{paninski2018neural}
\citation{kraynyukova2018stabilized}
\citation{morrison2016diversity}
\citation{litwin2016inhibitory}
\citation{GarciaDelMolino2017}
\citation{Chen2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Novel hypotheses from EPI}{19}}
\citation{pitkow2017inference}
\citation{echeveste2019cortical}
\citation{mastrogiuseppe2018linking}
\citation{richards2019deep}
\bibdata{eLife2020}
\bibcite{abbott2008theoretical}{1}
\bibcite{hopfield1982neural}{2}
\bibcite{sompolinsky1988chaos}{3}
\bibcite{tsodyks1997paradoxical}{4}
\bibcite{wong2006recurrent}{5}
\bibcite{liepe2014framework}{6}
\bibcite{kingma2013auto}{7}
\bibcite{rezende2014stochastic}{8}
\bibcite{gao2016linear}{9}
\bibcite{zhao2017recursive}{10}
\bibcite{barello2018sparse}{11}
\bibcite{pandarinath2018inferring}{12}
\bibcite{wiltschko2015mapping}{13}
\bibcite{johnson2016composing}{14}
\bibcite{batty2019behavenet}{15}
\bibcite{paninski2018neural}{16}
\bibcite{raue2009structural}{17}
\bibcite{gelman2013philosophy}{18}
\bibcite{blei2014build}{19}
\bibcite{transtrum2015perspective}{20}
\bibcite{tran2017hierarchical}{21}
\bibcite{rezende2015variational}{22}
\bibcite{dinh2016density}{23}
\bibcite{papamakarios2017masked}{24}
\bibcite{loaiza2017maximum}{25}
\bibcite{goldman2001global}{26}
\bibcite{gutierrez2013multiple}{27}
\bibcite{litwin2016inhibitory}{28}
\bibcite{duan2018collicular}{29}
\bibcite{mastrogiuseppe2018linking}{30}
\bibcite{marder2002cellular}{31}
\bibcite{prinz2004similar}{32}
\bibcite{jaynes1957information}{33}
\bibcite{elsayed2017structure}{34}
\bibcite{savin2017maximum}{35}
\bibcite{murphy2009balanced}{36}
\bibcite{ozeki2009inhibitory}{37}
\bibcite{rubin2015stabilized}{38}
\bibcite{markram2004interneurons}{39}
\bibcite{rudy2011three}{40}
\bibcite{tremblay2016}{41}
\bibcite{pfeffer2013inhibition}{42}
\bibcite{GarciaDelMolino2017}{43}
\bibcite{Chen2019}{44}
\bibcite{allen2018layer}{45}
\bibcite{billeh2019systematic}{46}
\bibcite{duan2015requirement}{47}
\bibcite{barak2017recurrent}{48}
\bibcite{sussillo2013opening}{49}
\bibcite{kass2001spike}{50}
\bibcite{brown1998statistical}{51}
\bibcite{paninski2004maximum}{52}
\bibcite{truccolo2005point}{53}
\bibcite{druckmann2007novel}{54}
\bibcite{byron2009gaussian}{55}
\bibcite{park2011bayesian}{56}
\bibcite{latimer2015single}{57}
\bibcite{lakshminarasimhan2018dynamic}{58}
\bibcite{duncker2019learning}{59}
\bibcite{ladenbauer2019inferring}{60}
\bibcite{kraynyukova2018stabilized}{61}
\bibcite{morrison2016diversity}{62}
\bibcite{pitkow2017inference}{63}
\bibcite{echeveste2019cortical}{64}
\bibcite{richards2019deep}{65}
\bibcite{blei2017variational}{66}
\bibcite{ranganath2014black}{67}
\bibcite{bittner2019degenerate}{68}
\bibcite{bittner2019examining}{69}
\bibcite{nonnenmacher2018sbi}{70}
\bibcite{desitler2019statistical}{71}
\bibcite{gonccalves2019training}{72}
\bibcite{LueckmannGoncalves_17}{73}
\bibcite{wainwright2008graphical}{74}
\bibcite{kingma2014adam}{75}
\bibcite{dinh2017density}{76}
\bibcite{brunel2000dynamics}{77}
\bibcite{jaeger2004harnessing}{78}
\bibcite{sussillo2009generating}{79}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Emergent property inference (EPI)}{29}}
\newlabel{methods_EPI}{{5.1}{29}}
\newlabel{eq:opt}{{16}{29}}
\citation{blei2017variational}
\citation{kingma2013auto}
\citation{ranganath2014black}
\citation{tran2017hierarchical}
\citation{bittner2019degenerate}
\citation{bittner2019examining}
\citation{nonnenmacher2018sbi}
\citation{desitler2019statistical}
\citation{gonccalves2019training}
\citation{loaiza2017maximum}
\citation{LueckmannGoncalves_17}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Related work}{30}}
\newlabel{methods_related}{{5.1.1}{30}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Normalizing flows}{30}}
\newlabel{methods_NF}{{5.1.2}{30}}
\citation{rezende2015variational}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Augmented Lagrangian optimization}{31}}
\newlabel{methods_AL_opt}{{5.1.3}{31}}
\newlabel{eq:AL}{{20}{31}}
\citation{wainwright2008graphical}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Maximum entropy distributions and exponential families}{33}}
\newlabel{methods_VI}{{5.1.4}{33}}
\newlabel{eq:max_ent}{{21}{33}}
\newlabel{eq:moments}{{25}{33}}
\newlabel{eq:mu_opt}{{26}{33}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}EPI as variational inference}{33}}
\newlabel{methods_exp_fam_lh}{{5.1.5}{33}}
\citation{blei2017variational}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.6}Example: 2D LDS}{35}}
\newlabel{methods_2DLDS}{{5.1.6}{35}}
\citation{wainwright2008graphical}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS1): A. Two-dimensional linear dynamical system model, where real entries of the dynamics matrix $A$ are the parameters. B. The EPI distribution for a two-dimensional linear dynamical system with $\tau =1$ that produces an average of 1Hz oscillations with some small amount of variance. Dashed lines indicate the parameter axes. C. Entropy throughout the optimization. At the beginning of each augmented Lagrangian epoch (2,000 iterations), the entropy dipped due to the shifted optimization manifold where emergent property constraint satisfaction is increasingly weighted. D. Emergent property moments throughout optimization. At the beginning of each augmented Lagrangian epoch, the emergent property moments adjust closer to their constraints.}}{37}}
\newlabel{fig:LDS1}{{5.1.6}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS2): A. Probability contours in the $a_1$-$a_4$ plane were derived from the relationship to emergent property statistic of growth/decay factor $\text  {real}(\lambda _1)$. B. Probability contours in the $a_2$-$a_3$ plane were derived from the emergent property statistic of oscillation frequency $2\pi \text  {imag}(\lambda _1)$.}}{38}}
\newlabel{fig:LDS2}{{5.1.6}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Theoretical models}{38}}
\newlabel{methods_theoretical_models}{{5.2}{38}}
\citation{gutierrez2013multiple}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (LDS3): Sampled dynamical systems $\mathbf  {z} \sim q_{\bm  {\theta }}(\mathbf  {z})$ and their simulated activity from $\mathbf  {x}(0) = [\frac  {\sqrt  {2}}{2}, -\frac  {\sqrt  {2}}{2}]$ colored by log probability. A. Each dimension of the simulated trajectories throughout time. B The simulated trajectories in phase space.}}{39}}
\newlabel{fig:LDS3}{{5.1.6}{39}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Stomatogastric ganglion}{39}}
\newlabel{methods_STG}{{5.2.1}{39}}
\citation{billeh2019systematic}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (STG1): EPI optimization of the STG model producing network syncing. A. Entropy throughout optimization. B. The emergent property statistic means and variances converge to their constraints at 25,000 iterations following the fifth augmented Lagrangian epoch.}}{42}}
\newlabel{fig:STG1}{{5.2.1}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Primary visual cortex}{42}}
\newlabel{methods_V1}{{5.2.2}{42}}
\citation{litwin2016inhibitory}
\citation{GarciaDelMolino2017}
\citation{Chen2019}
\newlabel{eq:V1_W}{{68}{43}}
\citation{duan2018collicular}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Superior colliculus}{45}}
\newlabel{methods_SC}{{5.2.3}{45}}
\citation{sompolinsky1988chaos}
\citation{brunel2000dynamics}
\citation{jaeger2004harnessing}
\citation{sussillo2009generating}
\citation{sompolinsky1988chaos}
\citation{mastrogiuseppe2018linking}
\newlabel{fig:SC}{{5.2.3}{47}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Rank-1 RNN}{47}}
\newlabel{methods_LRRNN}{{5.2.4}{47}}
\citation{mastrogiuseppe2018linking}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC1): Connectivity parameters of EPI distributions versus task accuracies. $\beta $ is slope coefficient of linear regression, $r$ is correlation, and $p$ is the two-tailed p value. }}{48}}
\newlabel{fig:SC1}{{10}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC2): A. Invariant eigenvectors of connectivity matrix $W$. B. Eigenvalues of connectivities of EPI distribution versus task accuracies.}}{49}}
\newlabel{fig:SC2}{{11}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC3): A. Connectitivy eigenvalues of EPI parameter distribution colored by Pro task accuracy. B. Same for Anti task. }}{49}}
\newlabel{fig:SC3}{{12}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC4): Scatters of the effect of delay period inactivation in each task with task accuracy. Plots are shown at an opto strength of 0.8. }}{50}}
\newlabel{fig:SC4}{{13}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip (SC5): EPI optimization of the SC model producing rapid task switching. A. Entropy throughout optimization. B. The emergent property statistic means and variances converge to their constraints at 12,000 iterations following the sixth augmented Lagrangian epoch. }}{50}}
\newlabel{fig:SC5}{{14}{50}}
