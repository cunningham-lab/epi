\begin{thebibliography}{100}

\bibitem{kopell1988coupled}
Nancy Kopell and G~Bard Ermentrout.
\newblock Coupled oscillators and the design of central pattern generators.
\newblock {\em Mathematical biosciences}, 90(1-2):87--109, 1988.

\bibitem{marder1998biophysics}
Eve Marder.
\newblock From biophysics to models of network function.
\newblock {\em Annual review of neuroscience}, 21(1):25--45, 1998.

\bibitem{abbott2008theoretical}
Larry~F Abbott.
\newblock Theoretical neuroscience rising.
\newblock {\em Neuron}, 60(3):489--495, 2008.

\bibitem{wang2010neurophysiological}
Xiao-Jing Wang.
\newblock Neurophysiological and computational principles of cortical rhythms
  in cognition.
\newblock {\em Physiological reviews}, 90(3):1195--1268, 2010.

\bibitem{gutenkunst2007universally}
Ryan~N Gutenkunst, Joshua~J Waterfall, Fergal~P Casey, Kevin~S Brown,
  Christopher~R Myers, and James~P Sethna.
\newblock Universally sloppy parameter sensitivities in systems biology models.
\newblock {\em PLoS Comput Biol}, 3(10):e189, 2007.

\bibitem{o2014cell}
Timothy O'Leary, Alex~H Williams, Alessio Franci, and Eve Marder.
\newblock Cell types, network homeostasis, and pathological compensation from a
  biologically plausible ion channel expression model.
\newblock {\em Neuron}, 82(4):809--821, 2014.

\bibitem{hopfield1982neural}
John~J Hopfield.
\newblock Neural networks and physical systems with emergent collective
  computational abilities.
\newblock {\em Proceedings of the national academy of sciences},
  79(8):2554--2558, 1982.

\bibitem{sompolinsky1988chaos}
Haim Sompolinsky, Andrea Crisanti, and Hans-Jurgen Sommers.
\newblock Chaos in random neural networks.
\newblock {\em Physical review letters}, 61(3):259, 1988.

\bibitem{tsodyks1997paradoxical}
Misha~V Tsodyks, William~E Skaggs, Terrence~J Sejnowski, and Bruce~L
  McNaughton.
\newblock Paradoxical effects of external modulation of inhibitory
  interneurons.
\newblock {\em Journal of neuroscience}, 17(11):4382--4388, 1997.

\bibitem{wong2006recurrent}
Kong-Fatt Wong and Xiao-Jing Wang.
\newblock A recurrent network mechanism of time integration in perceptual
  decisions.
\newblock {\em Journal of Neuroscience}, 26(4):1314--1328, 2006.

\bibitem{foster1993significance}
WR~Foster, LH~Ungar, and JS~Schwaber.
\newblock Significance of conductances in hodgkin-huxley models.
\newblock {\em Journal of neurophysiology}, 70(6):2502--2518, 1993.

\bibitem{prinz2004similar}
Astrid~A Prinz, Dirk Bucher, and Eve Marder.
\newblock Similar network activity from disparate circuit parameters.
\newblock {\em Nature neuroscience}, 7(12):1345--1352, 2004.

\bibitem{achard2006complex}
Pablo Achard and Erik De~Schutter.
\newblock Complex parameter landscape for a complex neuron model.
\newblock {\em PLoS computational biology}, 2(7):e94, 2006.

\bibitem{alonso2019visualization}
Leandro~M Alonso and Eve Marder.
\newblock Visualization of currents in neural models with similar behavior and
  different conductance densities.
\newblock {\em Elife}, 8:e42722, 2019.

\bibitem{kass2001spike}
Robert~E Kass and Val{\'e}rie Ventura.
\newblock A spike-train probability model.
\newblock {\em Neural computation}, 13(8):1713--1720, 2001.

\bibitem{brown1998statistical}
Emery~N Brown, Loren~M Frank, Dengda Tang, Michael~C Quirk, and Matthew~A
  Wilson.
\newblock A statistical paradigm for neural spike train decoding applied to
  position prediction from ensemble firing patterns of rat hippocampal place
  cells.
\newblock {\em Journal of Neuroscience}, 18(18):7411--7425, 1998.

\bibitem{paninski2004maximum}
Liam Paninski.
\newblock Maximum likelihood estimation of cascade point-process neural
  encoding models.
\newblock {\em Network: Computation in Neural Systems}, 15(4):243--262, 2004.

\bibitem{truccolo2005point}
Wilson Truccolo, Uri~T Eden, Matthew~R Fellows, John~P Donoghue, and Emery~N
  Brown.
\newblock A point process framework for relating neural spiking activity to
  spiking history, neural ensemble, and extrinsic covariate effects.
\newblock {\em Journal of neurophysiology}, 93(2):1074--1089, 2005.

\bibitem{schneidman2006weak}
Elad Schneidman, Michael~J Berry, Ronen Segev, and William Bialek.
\newblock Weak pairwise correlations imply strongly correlated network states
  in a neural population.
\newblock {\em Nature}, 440(7087):1007--1012, 2006.

\bibitem{druckmann2007novel}
Shaul Druckmann, Yoav Banitt, Albert~A Gidon, Felix Sch{\"u}rmann, Henry
  Markram, and Idan Segev.
\newblock A novel multiple objective optimization framework for constraining
  conductance-based neuron models by experimental data.
\newblock {\em Frontiers in neuroscience}, 1:1, 2007.

\bibitem{turner2007maximum}
Richard Turner and Maneesh Sahani.
\newblock A maximum-likelihood interpretation for slow feature analysis.
\newblock {\em Neural computation}, 19(4):1022--1038, 2007.

\bibitem{byron2009gaussian}
M~Yu Byron, John~P Cunningham, Gopal Santhanam, Stephen~I Ryu, Krishna~V
  Shenoy, and Maneesh Sahani.
\newblock Gaussian-process factor analysis for low-dimensional single-trial
  analysis of neural population activity.
\newblock In {\em Advances in neural information processing systems}, pages
  1881--1888, 2009.

\bibitem{macke2011empirical}
Jakob~H Macke, Lars Buesing, John~P Cunningham, Byron~M Yu, Krishna~V Shenoy,
  and Maneesh Sahani.
\newblock Empirical models of spiking in neural populations.
\newblock {\em Advances in neural information processing systems},
  24:1350--1358, 2011.

\bibitem{park2011bayesian}
Il~Memming Park and Jonathan~W Pillow.
\newblock Bayesian spike-triggered covariance analysis.
\newblock In {\em Advances in neural information processing systems}, pages
  1692--1700, 2011.

\bibitem{granot2013stimulus}
Einat Granot-Atedgi, Ga{\v{s}}per Tka{\v{c}}ik, Ronen Segev, and Elad
  Schneidman.
\newblock Stimulus-dependent maximum entropy models of neural population codes.
\newblock {\em PLoS Comput Biol}, 9(3):e1002922, 2013.

\bibitem{latimer2015single}
Kenneth~W Latimer, Jacob~L Yates, Miriam~LR Meister, Alexander~C Huk, and
  Jonathan~W Pillow.
\newblock Single-trial spike trains in parietal cortex reveal discrete steps
  during decision-making.
\newblock {\em Science}, 349(6244):184--187, 2015.

\bibitem{lakshminarasimhan2018dynamic}
Kaushik~J Lakshminarasimhan, Marina Petsalis, Hyeshin Park, Gregory~C
  DeAngelis, Xaq Pitkow, and Dora~E Angelaki.
\newblock A dynamic bayesian observer model reveals origins of bias in visual
  path integration.
\newblock {\em Neuron}, 99(1):194--206, 2018.

\bibitem{duncker2019learning}
Lea Duncker, Gergo Bohner, Julien Boussard, and Maneesh Sahani.
\newblock Learning interpretable continuous-time models of latent stochastic
  dynamical systems.
\newblock {\em Proceedings of the 36th International Conference on Machine
  Learning}, 2019.

\bibitem{ladenbauer2019inferring}
Josef Ladenbauer, Sam McKenzie, Daniel~Fine English, Olivier Hagens, and Srdjan
  Ostojic.
\newblock Inferring and validating mechanistic models of neural microcircuits
  based on spike-train data.
\newblock {\em Nature Communications}, 10(4933), 2019.

\bibitem{paninski2018neural}
Liam Paninski and John~P Cunningham.
\newblock Neural data science: accelerating the experiment-analysis-theory
  cycle in large-scale neuroscience.
\newblock {\em Current opinion in neurobiology}, 50:232--241, 2018.

\bibitem{sisson2007sequential}
Scott~A Sisson, Yanan Fan, and Mark~M Tanaka.
\newblock Sequential monte carlo without likelihoods.
\newblock {\em Proceedings of the National Academy of Sciences},
  104(6):1760--1765, 2007.

\bibitem{liepe2014framework}
Juliane Liepe, Paul Kirk, Sarah Filippi, Tina Toni, Chris~P Barnes, and
  Michael~PH Stumpf.
\newblock A framework for parameter estimation and model selection from
  experimental data in systems biology using approximate bayesian computation.
\newblock {\em Nature protocols}, 9(2):439--456, 2014.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em International Conference on Learning Representations}, 2014.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and variational inference in deep latent
  gaussian models.
\newblock {\em International Conference on Machine Learning}, 2014.

\bibitem{gao2016linear}
Yuanjun Gao, Evan~W Archer, Liam Paninski, and John~P Cunningham.
\newblock Linear dynamical neural population models through nonlinear
  embeddings.
\newblock In {\em Advances in neural information processing systems}, pages
  163--171, 2016.

\bibitem{zhao2017recursive}
Yuan Zhao and Il~Memming Park.
\newblock Recursive variational bayesian dual estimation for nonlinear dynamics
  and non-gaussian observations.
\newblock {\em stat}, 1050:27, 2017.

\bibitem{barello2018sparse}
Gabriel Barello, Adam Charles, and Jonathan Pillow.
\newblock Sparse-coding variational auto-encoders.
\newblock {\em bioRxiv}, page 399246, 2018.

\bibitem{pandarinath2018inferring}
Chethan Pandarinath, Daniel~J O'Shea, Jasmine Collins, Rafal Jozefowicz,
  Sergey~D Stavisky, Jonathan~C Kao, Eric~M Trautmann, Matthew~T Kaufman,
  Stephen~I Ryu, Leigh~R Hochberg, et~al.
\newblock Inferring single-trial neural population dynamics using sequential
  auto-encoders.
\newblock {\em Nature methods}, page~1, 2018.

\bibitem{wiltschko2015mapping}
Alexander~B Wiltschko, Matthew~J Johnson, Giuliano Iurilli, Ralph~E Peterson,
  Jesse~M Katon, Stan~L Pashkovski, Victoria~E Abraira, Ryan~P Adams, and
  Sandeep~Robert Datta.
\newblock Mapping sub-second structure in mouse behavior.
\newblock {\em Neuron}, 88(6):1121--1135, 2015.

\bibitem{johnson2016composing}
Matthew~J Johnson, David~K Duvenaud, Alex Wiltschko, Ryan~P Adams, and
  Sandeep~R Datta.
\newblock Composing graphical models with neural networks for structured
  representations and fast inference.
\newblock In {\em Advances in neural information processing systems}, pages
  2946--2954, 2016.

\bibitem{batty2019behavenet}
Eleanor Batty, Matthew Whiteway, Shreya Saxena, Dan Biderman, Taiga Abe, Simon
  Musall, Winthrop Gillis, Jeffrey Markowitz, Anne Churchland, John Cunningham,
  et~al.
\newblock Behavenet: nonlinear embedding and bayesian neural decoding of
  behavioral videos.
\newblock {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{beaumont2002approximate}
Mark~A Beaumont, Wenyang Zhang, and David~J Balding.
\newblock Approximate bayesian computation in population genetics.
\newblock {\em Genetics}, 162(4):2025--2035, 2002.

\bibitem{marjoram2003markov}
Paul Marjoram, John Molitor, Vincent Plagnol, and Simon Tavar{\'e}.
\newblock Markov chain monte carlo without likelihoods.
\newblock {\em Proceedings of the National Academy of Sciences},
  100(26):15324--15328, 2003.

\bibitem{hastings1970monte}
W~Keith Hastings.
\newblock Monte carlo sampling methods using markov chains and their
  applications.
\newblock 1970.

\bibitem{metropolis1953equation}
Nicholas Metropolis, Arianna~W Rosenbluth, Marshall~N Rosenbluth, Augusta~H
  Teller, and Edward Teller.
\newblock Equation of state calculations by fast computing machines.
\newblock {\em The journal of chemical physics}, 21(6):1087--1092, 1953.

\bibitem{saul1998mean}
Lawrence Saul and Michael Jordan.
\newblock A mean field learning algorithm for unsupervised neural networks.
\newblock In {\em Learning in graphical models}, pages 541--554. Springer,
  1998.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em International Conference on Machine Learning}, 2015.

\bibitem{transtrum2015perspective}
Mark~K Transtrum, Benjamin~B Machta, Kevin~S Brown, Bryan~C Daniels,
  Christopher~R Myers, and James~P Sethna.
\newblock Perspective: Sloppiness and emergent theories in physics, biology,
  and beyond.
\newblock {\em The Journal of chemical physics}, 143(1):07B201\_1, 2015.

\bibitem{tran2017hierarchical}
Dustin Tran, Rajesh Ranganath, and David Blei.
\newblock Hierarchical implicit models and likelihood-free variational
  inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5523--5533, 2017.

\bibitem{dinh2017density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock {\em Proceedings of the 5th International Conference on Learning
  Representations}, 2017.

\bibitem{papamakarios2017masked}
George Papamakarios, Theo Pavlakou, and Iain Murray.
\newblock Masked autoregressive flow for density estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2338--2347, 2017.

\bibitem{loaiza2017maximum}
Gabriel Loaiza-Ganem, Yuanjun Gao, and John~P Cunningham.
\newblock Maximum entropy flow networks.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{goldman2001global}
Mark~S Goldman, Jorge Golowasch, Eve Marder, and LF~Abbott.
\newblock Global structure, robustness, and modulation of neuronal models.
\newblock {\em Journal of Neuroscience}, 21(14):5229--5238, 2001.

\bibitem{litwin2016inhibitory}
Ashok Litwin-Kumar, Robert Rosenbaum, and Brent Doiron.
\newblock Inhibitory stabilization and visual coding in cortical circuits with
  multiple interneuron subtypes.
\newblock {\em Journal of neurophysiology}, 115(3):1399--1409, 2016.

\bibitem{duan2018collicular}
Chunyu~A Duan, Marino Pagan, Alex~T Piet, Charles~D Kopec, Athena Akrami,
  Alexander~J Riordan, Jeffrey~C Erlich, and Carlos~D Brody.
\newblock Collicular circuits for flexible sensorimotor routing.
\newblock {\em bioRxiv}, page 245613, 2018.

\bibitem{marder2002cellular}
Eve Marder and Vatsala Thirumalai.
\newblock Cellular, synaptic and network effects of neuromodulation.
\newblock {\em Neural Networks}, 15(4-6):479--493, 2002.

\bibitem{gutierrez2013multiple}
Gabrielle~J Gutierrez, Timothy O'Leary, and Eve Marder.
\newblock Multiple mechanisms switch an electrically coupled, synaptically
  inhibited neuron between competing rhythmic oscillators.
\newblock {\em Neuron}, 77(5):845--858, 2013.

\bibitem{jaynes1957information}
Edwin~T Jaynes.
\newblock Information theory and statistical mechanics.
\newblock {\em Physical review}, 106(4):620, 1957.

\bibitem{elsayed2017structure}
Gamaleldin~F Elsayed and John~P Cunningham.
\newblock Structure in neural population recordings: an expected byproduct of
  simpler phenomena?
\newblock {\em Nature neuroscience}, 20(9):1310, 2017.

\bibitem{savin2017maximum}
Cristina Savin and Ga{\v{s}}per Tka{\v{c}}ik.
\newblock Maximum entropy models as a tool for building precise neural
  controls.
\newblock {\em Current opinion in neurobiology}, 46:120--126, 2017.

\bibitem{goldman2009memory}
Mark~S Goldman.
\newblock Memory without feedback in a neural network.
\newblock {\em Neuron}, 61(4):621--634, 2009.

\bibitem{murphy2009balanced}
Brendan~K Murphy and Kenneth~D Miller.
\newblock Balanced amplification: a new mechanism of selective amplification of
  neural activity patterns.
\newblock {\em Neuron}, 61(4):635--648, 2009.

\bibitem{ozeki2009inhibitory}
Hirofumi Ozeki, Ian~M Finn, Evan~S Schaffer, Kenneth~D Miller, and David
  Ferster.
\newblock Inhibitory stabilization of the cortical network underlies visual
  surround suppression.
\newblock {\em Neuron}, 62(4):578--592, 2009.

\bibitem{rubin2015stabilized}
Daniel~B Rubin, Stephen~D Van~Hooser, and Kenneth~D Miller.
\newblock The stabilized supralinear network: a unifying circuit motif
  underlying multi-input integration in sensory cortex.
\newblock {\em Neuron}, 85(2):402--417, 2015.

\bibitem{markram2004interneurons}
Henry Markram, Maria Toledo-Rodriguez, Yun Wang, Anirudh Gupta, Gilad
  Silberberg, and Caizhi Wu.
\newblock Interneurons of the neocortical inhibitory system.
\newblock {\em Nature reviews neuroscience}, 5(10):793, 2004.

\bibitem{rudy2011three}
Bernardo Rudy, Gordon Fishell, SooHyun Lee, and Jens Hjerling-Leffler.
\newblock Three groups of interneurons account for nearly 100\% of neocortical
  gabaergic neurons.
\newblock {\em Developmental neurobiology}, 71(1):45--61, 2011.

\bibitem{tremblay2016}
Robin Tremblay, Soohyun Lee, and Bernardo Rudy.
\newblock {GABAergic Interneurons in the Neocortex: From Cellular Properties to
  Circuits}.
\newblock {\em Neuron}, 91(2):260--292, 2016.

\bibitem{pfeffer2013inhibition}
Carsten~K Pfeffer, Mingshan Xue, Miao He, Z~Josh Huang, and Massimo Scanziani.
\newblock Inhibition of inhibition in visual cortex: the logic of connections
  between molecularly distinct interneurons.
\newblock {\em Nature Neuroscience}, 16(8):1068, 2013.

\bibitem{GarciaDelMolino2017}
Luis~Carlos {Garcia Del Molino}, Guangyu~Robert Yang, Jorge~F. Mejias, and
  Xiao~Jing Wang.
\newblock {Paradoxical response reversal of top- down modulation in cortical
  circuits with three interneuron types}.
\newblock {\em Elife}, 6:1--15, 2017.

\bibitem{Chen2019}
Guang Chen, Carl~Van Vreeswijk, David Hansel, and David Hansel.
\newblock {Mechanisms underlying the response of mouse cortical networks to
  optogenetic manipulation}.
\newblock 2019.

\bibitem{hennequin2018dynamical}
Guillaume Hennequin, Yashar Ahmadian, Daniel~B Rubin, M{\'a}t{\'e} Lengyel, and
  Kenneth~D Miller.
\newblock The dynamical regime of sensory cortex: stable dynamics around a
  single stimulus-tuned attractor account for patterns of noise variability.
\newblock {\em Neuron}, 98(4):846--860, 2018.

\bibitem{palmigiano2020structure}
Agostina Palmigiano, Francesco Fumarola, Daniel~P Mossing, Nataliya
  Kraynyukova, Hillel Adesnik, and Kenneth Miller.
\newblock Structure and variability of optogenetic responses identify the
  operating regime of cortex.
\newblock {\em bioRxiv}, 2020.

\bibitem{duan2015requirement}
Chunyu~A Duan, Jeffrey~C Erlich, and Carlos~D Brody.
\newblock Requirement of prefrontal and midbrain regions for rapid executive
  control of behavior in the rat.
\newblock {\em Neuron}, 86(6):1491--1503, 2015.

\bibitem{bondanelli2020coding}
Giulio Bondanelli and Srdjan Ostojic.
\newblock Coding with transient trajectories in recurrent neural networks.
\newblock {\em PLoS computational biology}, 16(2):e1007655, 2020.

\bibitem{kraynyukova2018stabilized}
Nataliya Kraynyukova and Tatjana Tchumatchenko.
\newblock Stabilized supralinear network can give rise to bistable,
  oscillatory, and persistent activity.
\newblock {\em Proceedings of the National Academy of Sciences},
  115(13):3464--3469, 2018.

\bibitem{morrison2016diversity}
Katherine Morrison, Anda Degeratu, Vladimir Itskov, and Carina Curto.
\newblock Diversity of emergent dynamics in competitive threshold-linear
  networks: a preliminary report.
\newblock {\em arXiv preprint arXiv:1605.04463}, 2016.

\bibitem{pitkow2017inference}
Xaq Pitkow and Dora~E Angelaki.
\newblock Inference in the brain: statistics flowing in redundant population
  codes.
\newblock {\em Neuron}, 94(5):943--953, 2017.

\bibitem{echeveste2019cortical}
Rodrigo Echeveste, Laurence Aitchison, Guillaume Hennequin, and M{\'a}t{\'e}
  Lengyel.
\newblock Cortical-like dynamics in recurrent circuits optimized for
  sampling-based probabilistic inference.
\newblock {\em bioRxiv}, page 696088, 2019.

\bibitem{mastrogiuseppe2018linking}
Francesca Mastrogiuseppe and Srdjan Ostojic.
\newblock Linking connectivity, dynamics, and computations in low-rank
  recurrent neural networks.
\newblock {\em Neuron}, 99(3):609--623, 2018.

\bibitem{richards2019deep}
Blake~A Richards and et~al.
\newblock A deep learning framework for neuroscience.
\newblock {\em Nature Neuroscience}, 2019.

\bibitem{mlynarski2020statistical}
Wiktor M{\l}ynarski, Michal Hled{\'\i}k, Thomas~R Sokolowski, and Ga{\v{s}}per
  Tka{\v{c}}ik.
\newblock Statistical analysis and optimality of neural systems.
\newblock {\em bioRxiv}, page 848374, 2020.

\bibitem{girolami2011riemann}
Mark Girolami and Ben Calderhead.
\newblock Riemann manifold langevin and hamiltonian monte carlo methods.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 73(2):123--214, 2011.

\bibitem{golightly2011bayesian}
Andrew Golightly and Darren~J Wilkinson.
\newblock Bayesian parameter inference for stochastic biochemical network
  models using particle markov chain monte carlo.
\newblock {\em Interface focus}, 1(6):807--820, 2011.

\bibitem{cranmer2020frontier}
Kyle Cranmer, Johann Brehmer, and Gilles Louppe.
\newblock The frontier of simulation-based inference.
\newblock {\em Proceedings of the National Academy of Sciences}, 2020.

\bibitem{bittner2019degenerate}
Sean~R Bittner, Agostina Palmigiano, Kenneth~D Miller, and John~P Cunningham.
\newblock Degenerate solution networks for theoretical neuroscience.
\newblock {\em Computational and Systems Neuroscience Meeting (COSYNE), Lisbon,
  Portugal}, 2019.

\bibitem{bittner2019examining}
Sean~R Bittner, Alex~T Piet, Chunyu~A Duan, Agostina Palmigiano, Kenneth~D
  Miller, Carlos~D Brody, and John~P Cunningham.
\newblock Examining models in theoretical neuroscience with degenerate solution
  networks.
\newblock {\em Bernstein Conference 2019, Berlin, Germany}, 2019.

\bibitem{nonnenmacher2018sbi}
Marcel Nonnenmacher, Pedro~J Goncalves, Giacomo Bassetto, Jan-Matthis
  Lueckmann, and Jakob~H Macke.
\newblock Robust statistical inference for simulation-based models in
  neuroscience.
\newblock In {\em Bernstein Conference 2018, Berlin, Germany}, 2018.

\bibitem{desitler2019statistical}
Deistler Michael, , Pedro~J Goncalves, Kaan Oecal, and Jakob~H Macke.
\newblock Statistical inference for analyzing sloppiness in neuroscience
  models.
\newblock In {\em Bernstein Conference 2019, Berlin, Germany}, 2019.

\bibitem{gonccalves2019training}
Pedro~J Gon{\c{c}}alves, Jan-Matthis Lueckmann, Michael Deistler, Marcel
  Nonnenmacher, Kaan {\"O}cal, Giacomo Bassetto, Chaitanya Chintaluri,
  William~F Podlaski, Sara~A Haddad, Tim~P Vogels, et~al.
\newblock Training deep neural density estimators to identify mechanistic
  models of neural dynamics.
\newblock {\em bioRxiv}, page 838383, 2019.

\bibitem{LueckmannGoncalves_17}
Jan-Matthis Lueckmann, Pedro~J Goncalves, Giacomo Bassetto, Kaan {\"O}cal,
  Marcel Nonnenmacher, and Jakob~H Macke.
\newblock Flexible statistical inference for mechanistic models of neural
  dynamics.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1289--1299, 2017.

\bibitem{papamakarios2019sequential}
George Papamakarios, David Sterratt, and Iain Murray.
\newblock Sequential neural likelihood: Fast likelihood-free inference with
  autoregressive flows.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 837--848. PMLR, 2019.

\bibitem{hermans2020likelihood}
Joeri Hermans, Volodimir Begy, and Gilles Louppe.
\newblock Likelihood-free mcmc with amortized approximate ratio estimators.
\newblock In {\em International Conference on Machine Learning}, pages
  4239--4248. PMLR, 2020.

\bibitem{wainwright2008graphical}
Martin~J Wainwright, Michael~I Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  1(1--2):1--305, 2008.

\bibitem{bittner2019approximating}
Sean~R Bittner and John~P Cunningham.
\newblock Approximating exponential family models (not single distributions)
  with a two-network architecture.
\newblock {\em arXiv preprint arXiv:1903.07515}, 2019.

\bibitem{karlsson2012efficient}
Johan Karlsson, Milena Anguelova, and Mats Jirstrand.
\newblock An efficient method for structural identifiability analysis of large
  dynamic systems.
\newblock {\em IFAC Proceedings Volumes}, 45(16):941--946, 2012.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em Advances in neural information processing systems}, pages
  6571--6583, 2018.

\bibitem{li2020scalable}
Xuechen Li, Ting-Kam~Leonard Wong, Ricky~TQ Chen, and David Duvenaud.
\newblock Scalable gradients for stochastic differential equations.
\newblock {\em arXiv preprint arXiv:2001.01328}, 2020.

\bibitem{raue2009structural}
Andreas Raue, Clemens Kreutz, Thomas Maiwald, Julie Bachmann, Marcel Schilling,
  Ursula Klingm{\"u}ller, and Jens Timmer.
\newblock Structural and practical identifiability analysis of partially
  observed dynamical models by exploiting the profile likelihood.
\newblock {\em Bioinformatics}, 25(15):1923--1929, 2009.

\bibitem{raman2017delineating}
Dhruva~V Raman, James Anderson, and Antonis Papachristodoulou.
\newblock Delineating parameter unidentifiabilities in complex models.
\newblock {\em Physical Review E}, 95(3):032314, 2017.

\bibitem{saccomani2003parameter}
Maria~Pia Saccomani, Stefania Audoly, and Leontina D'Angi{\`o}.
\newblock Parameter identifiability of nonlinear systems: the role of initial
  conditions.
\newblock {\em Automatica}, 39(4):619--632, 2003.

\bibitem{papamakarios2019normalizing}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em arXiv preprint arXiv:1912.02762}, 2019.

\bibitem{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In {\em Advances in neural information processing systems}, pages
  10215--10224, 2018.

\bibitem{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock {\em Advances in neural information processing systems},
  29:4743--4751, 2016.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em International Conference on Learning Representations}, 2015.

\bibitem{blei2017variational}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock {\em Journal of the American Statistical Association},
  112(518):859--877, 2017.

\end{thebibliography}
